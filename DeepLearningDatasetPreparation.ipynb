{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7f8cfd",
   "metadata": {},
   "source": [
    "# Photoplethysmography (PPG) signal to indicate a critically ill patient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc4735",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "The objective of our project is to design a model for classification of photoplethysmography (PPG) signal to detect an elevated shock index which can indicate a critically ill patient.\n",
    "\n",
    "Keywords: photoplethysmography, shock index ,Signal extraction, Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbeac66",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "\n",
    "Source(url): https://pennstateoffice365-my.sharepoint.com/:f:/g/personal/yzb61_psu_edu/Eo4Q8j6bv0ZNk3i98SgIBRsB9fO9PHF7HwtbkHOoQPamag?e=10Sod7\n",
    "\n",
    "Short Description : Database used for this project was the MIMIC-IV Waveform Database which is a large collection of physiological signals and measurements from patients in intensive care units, including electrocardiograms, photoplethysmograms, respiration, invasive and non-invasive blood pressure, and more.\n",
    "\n",
    "Two types of data were collected by this project:\n",
    "\n",
    "1. waveform data, which consists of a high-resolution, regularly sampled time series, collected directly from a measuring device;\n",
    "\n",
    "2. numeric data, which consists of values that are either digitally derived (by software running on the bedside monitor, typically by analyzing one or more waveform signals), or sampled irregularly (such as non-invasive blood pressure).\n",
    "\n",
    "\n",
    "Keywords: photoplethysmography, shock index ,Signal extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9511b",
   "metadata": {},
   "source": [
    "## Required packages\n",
    "\n",
    "Below are a list of packages required :\n",
    "1. sys\n",
    "2. pathlib  Path\n",
    "3. pandas \n",
    "4. wfdb\n",
    "5. pprint\n",
    "6. scipy.signal \n",
    "7. matplotlib  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9cb139",
   "metadata": {},
   "source": [
    "\n",
    "# CODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'mimic4wdb/0.1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaa0973",
   "metadata": {},
   "source": [
    "# Create Empty Dataset with column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Heart_Rate', 'Systolic_blood_pressure(SBP)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e8cc4",
   "metadata": {},
   "source": [
    "# Identify the records in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd7a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each subject may be associated with multiple records\n",
    "subjects = wfdb.get_record_list(database_name)\n",
    "print(f\"The '{database_name}' database contains data from {len(subjects)} subjects\")\n",
    "\n",
    "# set max number of records to load\n",
    "max_records_to_load = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate the subjects to get a list of records\n",
    "records = []\n",
    "for subject in subjects:\n",
    "    studies = wfdb.get_record_list(f'{database_name}/{subject}')\n",
    "    for study in studies:\n",
    "        records.append(Path(f'{subject}{study}'))\n",
    "        # stop if we've loaded enough records\n",
    "        if len(records) >= max_records_to_load:\n",
    "            print(\"Reached maximum required number of records.\")\n",
    "            break\n",
    "\n",
    "print(f\"Loaded {len(records)} records from the '{database_name}' database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format and print first five records\n",
    "first_five_records = [str(x) for x in records[0:5]]\n",
    "first_five_records = \"\\n - \".join(first_five_records)\n",
    "print(f\"First five records: \\n - {first_five_records}\")\n",
    "\n",
    "print(\"\"\"\n",
    "Note the formatting of these records:\n",
    " - intermediate directory ('p100' in this case)\n",
    " - subject identifier (e.g. 'p10014354')\n",
    " - record identifier (e.g. '81739927'\n",
    " \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcaa4f6",
   "metadata": {},
   "source": [
    "# Extract metadata for a record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the 4th record (note, in Python indexing begins at 0)\n",
    "idx = 3\n",
    "record = records[idx]\n",
    "record_dir = f'{database_name}/{record.parent}'\n",
    "print(\"PhysioNet directory specified for record: {}\".format(record_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_name = record.name\n",
    "print(\"Record name: {}\".format(record_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae15c0",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7174414",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_names = ['83404654_0005']\n",
    "segment_dirs = ['mimic4wdb/0.1.0/waves/p100/p10020306/83404654']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_segment_no = 0\n",
    "rel_segment_name = segment_names[rel_segment_no]\n",
    "rel_segment_dir = segment_dirs[rel_segment_no]\n",
    "print(f\"Specified segment '{rel_segment_name}' in directory: '{rel_segment_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_data = wfdb.rdrecord(record_name=rel_segment_name, pn_dir=rel_segment_dir) \n",
    "print(f\"Data loaded from segment: {rel_segment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b469195",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data stored in class of type: {type(segment_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This segment contains waveform data for the following {segment_data.n_sig} signals: {segment_data.sig_name}\")\n",
    "print(f\"The signals are sampled at a base rate of {segment_data.fs} Hz (and some are sampled at multiples of this)\")\n",
    "print(f\"They last for {segment_data.sig_len/(60*segment_data.fs):.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e38b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(segment_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d989ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(segment_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810131b4",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time since the start of the segment at which to begin extracting data\n",
    "start_seconds = 20\n",
    "n_seconds_to_load = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa6626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_metadata = wfdb.rdheader(record_name=rel_segment_name,\n",
    "                                 pn_dir=rel_segment_dir)\n",
    "\n",
    "print(f\"Metadata loaded from segment: {rel_segment_name}\")\n",
    "fs = round(segment_metadata.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampfrom = fs * start_seconds\n",
    "sampto = fs * (start_seconds + n_seconds_to_load)\n",
    "\n",
    "segment_data = wfdb.rdrecord(record_name=rel_segment_name,\n",
    "                             sampfrom=sampfrom,\n",
    "                             sampto=sampto,\n",
    "                             pn_dir=rel_segment_dir)\n",
    "\n",
    "print(f\"{n_seconds_to_load} seconds of data extracted from segment {rel_segment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text = f\"Segment {rel_segment_name}\"\n",
    "wfdb.plot_wfdb(record=segment_data,\n",
    "               title=title_text,\n",
    "               time_units='seconds') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cade3f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig_no in range(0, len(segment_data.sig_name)):\n",
    "    if \"Pleth\" in segment_data.sig_name[sig_no]:\n",
    "        break\n",
    "\n",
    "ppg = segment_data.p_signal[:, sig_no]\n",
    "fs = segment_data.fs\n",
    "print(f\"Extracted the PPG signal from column {sig_no} of the matrix of waveform data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6695657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "t = np.arange(0, (len(ppg) / fs), 1.0 / fs)\n",
    "plt.plot(t, ppg, color = 'black', label='PPG')\n",
    "plt.xlim([50, 55])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c28e31",
   "metadata": {},
   "source": [
    "# Filtering Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa83535",
   "metadata": {},
   "source": [
    "We then filter the PPG signal:\n",
    "\n",
    "1. Filtering is used to eliminate noise from physiological signals. For instance, ECG signals can contain mains frequency noise due to electrical interference.\n",
    "\n",
    "2. We filter signals using the SciPy signal processing package to interpret the amplitude-response of a filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719eb497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment for analysis\n",
    "segment_names = ['83404654_0005',\n",
    "                 '82924339_0007']\n",
    "\n",
    "segment_dirs = ['mimic4wdb/0.1.0/waves/p100/p10020306/83404654',\n",
    "                'mimic4wdb/0.1.0/waves/p101/p10126957/82924339']\n",
    "\n",
    "rel_segment_n = 0\n",
    "rel_segment_name = segment_names[rel_segment_n]\n",
    "rel_segment_dir = segment_dirs[rel_segment_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2fbb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time since the start of the segment at which to begin extracting data\n",
    "start_seconds = 20 \n",
    "n_seconds_to_load = 60\n",
    "\n",
    "segment_metadata = wfdb.rdheader(record_name=rel_segment_name, pn_dir=rel_segment_dir) \n",
    "print(f\"Metadata loaded from segment: {rel_segment_name}\")\n",
    "\n",
    "fs = round(segment_metadata.fs)\n",
    "sampfrom = fs*start_seconds\n",
    "sampto = fs*(start_seconds + n_seconds_to_load)\n",
    "\n",
    "segment_data = wfdb.rdrecord(record_name=rel_segment_name,\n",
    "                             sampfrom=sampfrom,\n",
    "                             sampto=sampto,\n",
    "                             pn_dir=rel_segment_dir)\n",
    "\n",
    "print(f\"{n_seconds_to_load} seconds of data extracted from: {rel_segment_name}\")\n",
    "\n",
    "for sig_no in range(0, len(segment_data.sig_name)):\n",
    "    if \"Pleth\" in segment_data.sig_name[sig_no]:\n",
    "        break\n",
    "\n",
    "ppg = segment_data.p_signal[:,sig_no]\n",
    "fs = segment_data.fs\n",
    "print(f\"Extracted the PPG signal from column {sig_no} of the matrix of waveform data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb8298",
   "metadata": {},
   "source": [
    "### Create a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify cutoff in Hertz\n",
    "lpf_cutoff = 0.7 \n",
    "hpf_cutoff = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a887a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_ppg = sp.butter(10,\n",
    "                    [lpf_cutoff, hpf_cutoff],\n",
    "                    btype = 'bp',\n",
    "                    analog = False,\n",
    "                    output = 'sos',\n",
    "                    fs = segment_data.fs)\n",
    "\n",
    "w, h = sp.sosfreqz(sos_ppg,\n",
    "                   2000,\n",
    "                   fs = fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(w, 20 * np.log10(np.maximum(abs(h), 1e-5)))\n",
    "\n",
    "ax.set_title('Butterworth bandpass filter frequency response')\n",
    "ax.set_xlabel('Frequency [Hz]')\n",
    "ax.set_ylabel('Amplitude [dB]')\n",
    "ax.axis((0, 20, -100, 10))\n",
    "ax.grid(which='both',\n",
    "        axis='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c000ed6",
   "metadata": {},
   "source": [
    "# Filter the PPG signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1cae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_filt = sp.sosfiltfilt(sos_ppg, ppg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea6dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "t = np.arange(0, len(ppg_filt))/segment_data.fs\n",
    "\n",
    "ax.plot(t, ppg,\n",
    "        linewidth=2.0,\n",
    "        color = 'blue',\n",
    "        label = \"original PPG\")\n",
    "\n",
    "ax.plot(t, ppg_filt,\n",
    "        linewidth=2.0,\n",
    "        color = 'red',\n",
    "        label = \"filtered PPG\")\n",
    "\n",
    "ax.set(xlim=(0, n_seconds_to_load))\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('PPG')\n",
    "plt.xlim([50, 60])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a43fe0",
   "metadata": {},
   "source": [
    "# Differentiating the PPG signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e4a79",
   "metadata": {},
   "source": [
    "We then move onto differentiating the PPG signal:\n",
    "\n",
    "1. Differentiating the PPG signal is a key step in identifying fiducial points on PPG pulse waves.\n",
    "\n",
    "2. Apply SciPy functions for differentiating signals to view typical shapes of the first and second derivatives of PPG signals.\n",
    "\n",
    "3. PPG waveform comes with four main fiducial points of onset (foot), systolic peak, dicrotic notch, and diastolic peak. This is shown in below Figure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd4848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment for analysis\n",
    "segment_names = ['83404654_0005', '82924339_0007', '84248019_0005', '82439920_0004', '82800131_0002', '84304393_0001', '89464742_0001', '88958796_0004', '88995377_0001', '85230771_0004', '86643930_0004', '81250824_0005', '87706224_0003', '83058614_0005', '82803505_0017', '88574629_0001', '87867111_0012', '84560969_0001', '87562386_0001', '88685937_0001', '86120311_0001', '89866183_0014', '89068160_0002', '86380383_0001', '85078610_0008', '87702634_0007', '84686667_0002', '84802706_0002', '81811182_0004', '84421559_0005', '88221516_0007', '80057524_0005', '84209926_0018', '83959636_0010', '89989722_0016', '89225487_0007', '84391267_0001', '80889556_0002', '85250558_0011', '84567505_0005', '85814172_0007', '88884866_0005', '80497954_0012', '80666640_0014', '84939605_0004', '82141753_0018', '86874920_0014', '84505262_0010', '86288257_0001', '89699401_0001', '88537698_0013', '83958172_0001']\n",
    "segment_dirs = ['mimic4wdb/0.1.0/waves/p100/p10020306/83404654', 'mimic4wdb/0.1.0/waves/p101/p10126957/82924339', 'mimic4wdb/0.1.0/waves/p102/p10209410/84248019', 'mimic4wdb/0.1.0/waves/p109/p10952189/82439920', 'mimic4wdb/0.1.0/waves/p111/p11109975/82800131', 'mimic4wdb/0.1.0/waves/p113/p11392990/84304393', 'mimic4wdb/0.1.0/waves/p121/p12168037/89464742', 'mimic4wdb/0.1.0/waves/p121/p12173569/88958796', 'mimic4wdb/0.1.0/waves/p121/p12188288/88995377', 'mimic4wdb/0.1.0/waves/p128/p12872596/85230771', 'mimic4wdb/0.1.0/waves/p129/p12933208/86643930', 'mimic4wdb/0.1.0/waves/p130/p13016481/81250824', 'mimic4wdb/0.1.0/waves/p132/p13240081/87706224', 'mimic4wdb/0.1.0/waves/p136/p13624686/83058614', 'mimic4wdb/0.1.0/waves/p137/p13791821/82803505', 'mimic4wdb/0.1.0/waves/p141/p14191565/88574629', 'mimic4wdb/0.1.0/waves/p142/p14285792/87867111', 'mimic4wdb/0.1.0/waves/p143/p14356077/84560969', 'mimic4wdb/0.1.0/waves/p143/p14363499/87562386', 'mimic4wdb/0.1.0/waves/p146/p14695840/88685937', 'mimic4wdb/0.1.0/waves/p149/p14931547/86120311', 'mimic4wdb/0.1.0/waves/p151/p15174162/89866183', 'mimic4wdb/0.1.0/waves/p153/p15312343/89068160', 'mimic4wdb/0.1.0/waves/p153/p15342703/86380383', 'mimic4wdb/0.1.0/waves/p155/p15552902/85078610', 'mimic4wdb/0.1.0/waves/p156/p15649186/87702634', 'mimic4wdb/0.1.0/waves/p158/p15857793/84686667', 'mimic4wdb/0.1.0/waves/p158/p15865327/84802706', 'mimic4wdb/0.1.0/waves/p158/p15896656/81811182', 'mimic4wdb/0.1.0/waves/p159/p15920699/84421559', 'mimic4wdb/0.1.0/waves/p160/p16034243/88221516', 'mimic4wdb/0.1.0/waves/p165/p16566444/80057524', 'mimic4wdb/0.1.0/waves/p166/p16644640/84209926', 'mimic4wdb/0.1.0/waves/p167/p16709726/83959636', 'mimic4wdb/0.1.0/waves/p167/p16715341/89989722', 'mimic4wdb/0.1.0/waves/p168/p16818396/89225487', 'mimic4wdb/0.1.0/waves/p170/p17032851/84391267', 'mimic4wdb/0.1.0/waves/p172/p17229504/80889556', 'mimic4wdb/0.1.0/waves/p173/p17301721/85250558', 'mimic4wdb/0.1.0/waves/p173/p17325001/84567505', 'mimic4wdb/0.1.0/waves/p174/p17490822/85814172', 'mimic4wdb/0.1.0/waves/p177/p17738824/88884866', 'mimic4wdb/0.1.0/waves/p177/p17744715/80497954', 'mimic4wdb/0.1.0/waves/p179/p17957832/80666640', 'mimic4wdb/0.1.0/waves/p180/p18080257/84939605', 'mimic4wdb/0.1.0/waves/p181/p18109577/82141753', 'mimic4wdb/0.1.0/waves/p183/p18324626/86874920', 'mimic4wdb/0.1.0/waves/p187/p18742074/84505262', 'mimic4wdb/0.1.0/waves/p188/p18824975/86288257', 'mimic4wdb/0.1.0/waves/p191/p19126489/89699401', 'mimic4wdb/0.1.0/waves/p193/p19313794/88537698', 'mimic4wdb/0.1.0/waves/p196/p19619764/83958172']\n",
    "\n",
    "# Segment 3 and 8 are helpful\n",
    "rel_segment_n = 8 \n",
    "rel_segment_name = segment_names[rel_segment_n]\n",
    "rel_segment_dir = segment_dirs[rel_segment_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time since the start of the segment at which to begin extracting data\n",
    "start_seconds = 100 \n",
    "no_seconds_to_load = 5\n",
    "\n",
    "segment_metadata = wfdb.rdheader(record_name=rel_segment_name,\n",
    "                                 pn_dir=rel_segment_dir) \n",
    "print(f\"Metadata loaded from segment: {rel_segment_name}\")\n",
    "\n",
    "fs = round(segment_metadata.fs)\n",
    "sampfrom = fs*start_seconds\n",
    "sampto = fs*(start_seconds + no_seconds_to_load)\n",
    "\n",
    "segment_data = wfdb.rdrecord(record_name=rel_segment_name,\n",
    "                             sampfrom=sampfrom,\n",
    "                             sampto=sampto,\n",
    "                             pn_dir=rel_segment_dir) \n",
    "\n",
    "print(f\"{no_seconds_to_load} seconds of data extracted from: {rel_segment_name}\")\n",
    "\n",
    "for sig_no in range(0, len(segment_data.sig_name)):\n",
    "    if \"Pleth\" in segment_data.sig_name[sig_no]:\n",
    "        break\n",
    "\n",
    "ppg = segment_data.p_signal[:,sig_no]\n",
    "fs = segment_data.fs\n",
    "\n",
    "print(f\"Extracted the PPG signal from column {sig_no} of the matrix of waveform data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package\n",
    "import scipy.signal as sp\n",
    "\n",
    "# filter cut-offs\n",
    "lpf_cutoff = 0.7 # Hz\n",
    "hpf_cutoff = 10 # Hz\n",
    "\n",
    "# create filter\n",
    "sos_ppg = sp.butter(10, [lpf_cutoff, hpf_cutoff],\n",
    "                    btype = 'bp',\n",
    "                    analog = False,\n",
    "                    output = 'sos',\n",
    "                    fs = segment_data.fs)\n",
    "\n",
    "w, h = sp.sosfreqz(sos_ppg, 2000, fs = fs)\n",
    "\n",
    "# filter PPG\n",
    "ppg_filt = sp.sosfiltfilt(sos_ppg, ppg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99705abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "t = np.arange(0, len(ppg_filt)) / segment_data.fs\n",
    "\n",
    "ax.plot(t, ppg,\n",
    "        linewidth=2.0,\n",
    "        label = \"original PPG\")\n",
    "\n",
    "ax.plot(t, ppg_filt,\n",
    "        linewidth=2.0,\n",
    "        label = \"filtered PPG\")\n",
    "\n",
    "ax.set(xlim=(0, no_seconds_to_load))\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('PPG')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f55879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate first derivative\n",
    "d1ppg = sp.savgol_filter(ppg_filt, 9, 5, deriv=1)\n",
    "\n",
    "# Calculate second derivative\n",
    "d2ppg = sp.savgol_filter(ppg_filt, 9, 5, deriv=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5288d360",
   "metadata": {},
   "source": [
    "### Plot the PPG and its derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ed5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0, len(ppg_filt))/segment_data.fs\n",
    "\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(3, 1, sharex = True, sharey = False)\n",
    "ax1.plot(t, ppg_filt)\n",
    "ax1.set(xlabel = '', ylabel = 'PPG')\n",
    "\n",
    "plt.suptitle('The PPG signal and its first and second derivatives')\n",
    "\n",
    "ax2.plot(t, d1ppg)\n",
    "ax2.set(xlabel = '',\n",
    "        ylabel = 'PPG\\'')\n",
    "\n",
    "ax3.plot(t, d2ppg)\n",
    "ax3.set(xlabel = 'Time (s)',\n",
    "        ylabel = 'PPG\\'\\'')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c47b9",
   "metadata": {},
   "source": [
    "# Heart Beat Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21634cf4",
   "metadata": {},
   "source": [
    "We now proceed with beat detection:\n",
    "\n",
    "1. A key step in analysing PPG signals is the detection of beats in the signals. This allows individual pulse waves to be analysed.\n",
    "\n",
    "2. Call Python functions that are stored in a separate file and use beat detection algorithm to detect beats in PPG signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as sp\n",
    "import numpy as np\n",
    "\n",
    "def pulse_detect(x,fs,w,alg):\n",
    "    \"\"\"\n",
    "    Description: Pulse detection and correction from pulsatile signals\n",
    "    Inputs:  x, array with pulsatile signal [user defined units]\n",
    "             fs, sampling rate of signal [Hz]\n",
    "             w, window length for analysis [s]\n",
    "             alg, string with the name of the algorithm to apply ['heartpy','d2max','upslopes','delineator']\n",
    "    Outputs: ibis, location of cardiac cycles as detected by the selected algorithm [number of samples]\n",
    "\n",
    "    Algorithms:       1: HeartPy (van Gent et al, 2019, DOI: 10.1016/j.trf.2019.09.015)\n",
    "                      2: 2nd derivative maxima (Elgendi et al, 2013, DOI: 10.1371/journal.pone.0076585)\n",
    "                      3: Systolic upslopes (Arguello Prada and Serna Maldonado, 2018,\n",
    "                         DOI: 10.1080/03091902.2019.1572237)\n",
    "                      4: Delineator (Li et al, 2010, DOI: 10.1109/TBME.2005.855725)\n",
    "    Fiducial points:  1: Systolic peak (pks)\n",
    "                      2: Onset, as the minimum before the systolic peak (ons)\n",
    "                      3: Onset, using the tangent intersection method (ti)\n",
    "                      4: Diastolic peak (dpk)\n",
    "                      5: Maximum slope (m1d)\n",
    "                      6: a point from second derivative PPG (a2d)\n",
    "                      7: b point from second derivative PPG (b2d)\n",
    "                      8: c point from second derivative PPG (c2d)\n",
    "                      9: d point from second derivative PPG (d2d)\n",
    "                      10: e point from second derivative PPG (e2d)\n",
    "                      11: p1 from the third derivative PPG (p1)\n",
    "                      12: p2 from the third derivative PPG (p2)\n",
    "\n",
    "    Libraries: NumPy (as np), SciPy (Signal, as sp), Matplotlib (PyPlot, as plt)\n",
    "\n",
    "    Version: 1.0 - June 2022\n",
    "\n",
    "    Developed by: Elisa Mejía-Mejía\n",
    "                   City, University of London\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check selected algorithm\n",
    "    pos_alg = ['heartpy','d2max','upslopes','delineator']\n",
    "    if not(alg in pos_alg):\n",
    "        print('Unknown algorithm determined. Using D2max as default')\n",
    "        alg = 'd2max'\n",
    "\n",
    "    # Pre-processing of signal\n",
    "    x_d = sp.detrend(x)\n",
    "    sos = sp.butter(10, [0.5, 10], btype = 'bp', analog = False, output = 'sos', fs = fs)\n",
    "    x_f = sp.sosfiltfilt(sos, x_d)\n",
    "\n",
    "    # Peak detection in windows of length w\n",
    "    n_int = np.floor(len(x_f)/(w*fs))\n",
    "    for i in range(int(n_int)):\n",
    "        start = i*fs*w\n",
    "        stop = (i + 1)*fs*w - 1\n",
    "        # print('Start: ' + str(start) + ', stop: ' + str(stop) + ', fs: ' + str(fs))\n",
    "        aux = x_f[range(start,stop)]\n",
    "        if alg == 'heartpy':\n",
    "            locs = heartpy(aux,fs,40,180,5)\n",
    "        elif alg == 'd2max':\n",
    "            locs = d2max(aux,fs)\n",
    "        elif alg == 'upslopes':\n",
    "            locs = upslopes(aux)\n",
    "        elif alg == 'delineator':\n",
    "            locs = delineator(aux,fs)\n",
    "        locs = locs + start\n",
    "        if i == 0:\n",
    "            ibis = locs\n",
    "        else:\n",
    "            ibis = np.append(ibis,locs)\n",
    "    if n_int*fs*w != len(x_f):\n",
    "        start = stop + 1\n",
    "        stop = len(x_f)\n",
    "        aux = x_f[range(start,stop)]\n",
    "        if len(aux) > 20:\n",
    "            if alg == 'heartpy':\n",
    "                locs = heartpy(aux,fs,40,180,5)\n",
    "            elif alg == 'd2max':\n",
    "                locs = d2max(aux,fs)\n",
    "            elif alg == 'upslopes':\n",
    "                locs = upslopes(aux)\n",
    "            elif alg == 'delineator':\n",
    "                locs = delineator(aux,fs)\n",
    "            locs = locs + start\n",
    "            ibis = np.append(ibis,locs)\n",
    "    ind, = np.where(ibis <= len(x_f))\n",
    "    ibis = ibis[ind]\n",
    "\n",
    "    ibis = peak_correction(x,ibis,fs,20,5,[0.5, 1.5])\n",
    "\n",
    "    #fig = plt.figure()\n",
    "    #plt.plot(x)\n",
    "    #plt.plot(x_d)\n",
    "    #plt.plot(x_f)\n",
    "    #plt.scatter(ibis,x_f[ibis],marker = 'o',color = 'red')\n",
    "    #plt.scatter(ibis,x[ibis],marker = 'o',color = 'red')\n",
    "\n",
    "    return ibis\n",
    "\n",
    "def peak_correction(x,locs,fs,t,stride,th_len):\n",
    "    \"\"\"\n",
    "    Correction of peaks detected from pulsatile signals\n",
    "\n",
    "    Inputs:   x, pulsatile signal [user defined units]\n",
    "              locs, location of the detected interbeat intervals [number of samples]\n",
    "              fs, sampling rate [Hz]\n",
    "              t, duration of intervals for the correction [s]\n",
    "              stride, stride between consecutive intervals for the correction [s]\n",
    "              th_len, array with the percentage of lower and higher thresholds for comparing the duration of IBIs\n",
    "              [proportions]\n",
    "    Outputs:  ibis, array with the corrected points related to the start of the inter-beat intervals [number of samples]\n",
    "\n",
    "    Developed by:  Elisa Mejía Mejía\n",
    "                   City, University of London\n",
    "    Version:       1.0 -   June, 2022\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #fig = plt.figure()\n",
    "    #plt.plot(x)\n",
    "    #plt.scatter(locs,x[locs],marker = 'o',color = 'red', label = 'Original')\n",
    "    #plt.title('Peak correction')\n",
    "\n",
    "    # Correction of long and short IBIs\n",
    "    len_window = np.round(t*fs)\n",
    "    #print('Window length: ' + str(len_window))\n",
    "    first_i = 0\n",
    "    second_i = len_window - 1\n",
    "    while second_i < len(x):\n",
    "        ind1, = np.where(locs >= first_i)\n",
    "        ind2, = np.where(locs <= second_i)\n",
    "        ind = np.intersect1d(ind1, ind2)\n",
    "\n",
    "        win = locs[ind]\n",
    "        dif = np.diff(win)\n",
    "        #print('Indices: ' + str(ind) + ', locs: ' + str(locs[ind]) + ', dif: ' + str(dif))\n",
    "\n",
    "        th_dif = np.zeros(2)\n",
    "        th_dif[0] = th_len[0]*np.median(dif)\n",
    "        th_dif[1] = th_len[1]*np.median(dif)\n",
    "\n",
    "        th_amp = np.zeros(2)\n",
    "        th_amp[0] = 0.75*np.median(x[win])\n",
    "        th_amp[1] = 1.25*np.median(x[win])\n",
    "        #print('Length thresholds: ' + str(th_dif) + ', amplitude thresholds: ' + str(th_amp))\n",
    "\n",
    "        j = 0\n",
    "        while j < len(dif):\n",
    "            if dif[j] <= th_dif[0]:\n",
    "                if j == 0:\n",
    "                    opt = np.append(win[j], win[j + 1])\n",
    "                else:\n",
    "                    opt = np.append(win[j], win[j + 1]) - win[j - 1]\n",
    "                print('Optional: ' + str(opt))\n",
    "                dif_abs = np.abs(opt - np.median(dif))\n",
    "                min_val = np.min(dif_abs)\n",
    "                ind_min, = np.where(dif_abs == min_val)\n",
    "                print('Minimum: ' + str(min_val) + ', index: ' + str(ind_min))\n",
    "                if ind_min == 0:\n",
    "                    print('Original window: ' + str(win), end = '')\n",
    "                    win = np.delete(win, win[j + 1])\n",
    "                    print(', modified window: ' + str(win))\n",
    "                else:\n",
    "                    print('Original window: ' + str(win), end = '')\n",
    "                    win = np.delete(win, win[j])\n",
    "                    print(', modified window: ' + str(win))\n",
    "                dif = np.diff(win)\n",
    "            elif dif[j] >= th_dif[1]:\n",
    "                aux_x = x[win[j]:win[j + 1]]\n",
    "                locs_pks, _ = sp.find_peaks(aux_x)\n",
    "                #fig = plt.figure()\n",
    "                #plt.plot(aux_x)\n",
    "                #plt.scatter(locs_pks,aux_x[locs_pks],marker = 'o',color = 'red')\n",
    "\n",
    "                locs_pks = locs_pks + win[j]\n",
    "                ind1, = np.where(x[locs_pks] >= th_amp[0])\n",
    "                ind2, = np.where(x[locs_pks] <= th_amp[1])\n",
    "                ind = np.intersect1d(ind1, ind2)\n",
    "                locs_pks = locs_pks[ind]\n",
    "                #print('Locations: ' + str(locs_pks))\n",
    "\n",
    "                if len(locs_pks) != 0:\n",
    "                    opt = locs_pks - win[j]\n",
    "\n",
    "                    dif_abs = np.abs(opt - np.median(dif))\n",
    "                    min_val = np.min(dif_abs)\n",
    "                    ind_min, = np.where(dif_abs == min_val)\n",
    "\n",
    "                    win = np.append(win, locs_pks[ind_min])\n",
    "                    win = np.sort(win)\n",
    "                    dif = np.diff(win)\n",
    "                    j = j + 1\n",
    "                else:\n",
    "                    opt = np.round(win[j] + np.median(dif))\n",
    "                    if opt < win[j + 1]:\n",
    "                        win = np.append(win, locs_pks[ind_min])\n",
    "                        win = np.sort(win)\n",
    "                        dif = np.diff(win)\n",
    "                        j = j + 1\n",
    "                    else:\n",
    "                        j = j + 1\n",
    "            else:\n",
    "                j = j + 1\n",
    "\n",
    "        locs = np.append(win, locs)\n",
    "        locs = np.sort(locs)\n",
    "\n",
    "        first_i = first_i + stride*fs - 1\n",
    "        second_i = second_i + stride*fs - 1\n",
    "\n",
    "    dif = np.diff(locs)\n",
    "    dif = np.append(0, dif)\n",
    "    ind, = np.where(dif != 0)\n",
    "    locs = locs[ind]\n",
    "\n",
    "    #plt.scatter(locs,x[locs],marker = 'o',color = 'green', label = 'After length correction')\n",
    "\n",
    "    # Correction of points that are not peaks\n",
    "    i = 0\n",
    "    pre_loc = 0\n",
    "    while i < len(locs):\n",
    "        if locs[i] == 0:\n",
    "            locs = np.delete(locs, locs[i])\n",
    "        elif locs[i] == len(x):\n",
    "            locs = np.delete(locs, locs[i])\n",
    "        else:\n",
    "            #print('Previous: ' + str(x[locs[i] - 1]) + ', actual: ' + str(x[locs[i]]) + ', next: ' + str(x[locs[i] + 1]))\n",
    "            cond = (x[locs[i]] >= x[locs[i] - 1]) and (x[locs[i]] >= x[locs[i] + 1])\n",
    "            #print('Condition: ' + str(cond))\n",
    "            if cond:\n",
    "                i = i + 1\n",
    "            else:\n",
    "                if locs[i] == pre_loc:\n",
    "                    i = i + 1\n",
    "                else:\n",
    "                    if i == 0:\n",
    "                        aux = x[0:locs[i + 1] - 1]\n",
    "                        aux_loc = locs[i] - 1\n",
    "                        aux_start = 0\n",
    "                    elif i == len(locs) - 1:\n",
    "                        aux = x[locs[i - 1]:len(x) - 1]\n",
    "                        aux_loc = locs[i] - locs[i - 1]\n",
    "                        aux_start = locs[i - 1]\n",
    "                    else:\n",
    "                        aux = x[locs[i - 1]:locs[i + 1]]\n",
    "                        aux_loc = locs[i] - locs[i - 1]\n",
    "                        aux_start = locs[i - 1]\n",
    "                    #print('i ' + str(i) + ' out of ' + str(len(locs)) + ', aux length: ' + str(len(aux)) +\n",
    "                    #      ', location: ' + str(aux_loc))\n",
    "                    #print('Locs i - 1: ' + str(locs[i - 1]) + ', locs i: ' + str(locs[i]) + ', locs i + 1: ' + str(locs[i + 1]))\n",
    "\n",
    "                    pre = find_closest_peak(aux, aux_loc, 'backward')\n",
    "                    pos = find_closest_peak(aux, aux_loc, 'forward')\n",
    "                    #print('Previous: ' + str(pre) + ', next: ' + str(pos) + ', actual: ' + str(aux_loc))\n",
    "\n",
    "                    ibi_pre = np.append(pre - 1, len(aux) - pre)\n",
    "                    ibi_pos = np.append(pos - 1, len(aux) - pos)\n",
    "                    ibi_act = np.append(aux_loc - 1, len(aux) - aux_loc)\n",
    "                    #print('Previous IBIs: ' + str(ibi_pre) + ', next IBIs: ' + str(ibi_pos) +\n",
    "                    #      ', actual IBIs: ' + str(ibi_act))\n",
    "\n",
    "                    dif_pre = np.abs(ibi_pre - np.mean(np.diff(locs)))\n",
    "                    dif_pos = np.abs(ibi_pos - np.mean(np.diff(locs)))\n",
    "                    dif_act = np.abs(ibi_act - np.mean(np.diff(locs)))\n",
    "                    #print('Previous DIF: ' + str(dif_pre) + ', next DIF: ' + str(dif_pos) +\n",
    "                    #      ', actual DIF: ' + str(dif_act))\n",
    "\n",
    "                    avgs = [np.mean(dif_pre), np.mean(dif_pos), np.mean(dif_act)]\n",
    "                    min_avg = np.min(avgs)\n",
    "                    ind, = np.where(min_avg == avgs)\n",
    "                    #print('Averages: ' + str(avgs) + ', min index: ' + str(ind))\n",
    "                    if len(ind) != 0:\n",
    "                        ind = ind[0]\n",
    "\n",
    "                    if ind == 0:\n",
    "                        locs[i] = pre + aux_start - 1\n",
    "                    elif ind == 1:\n",
    "                        locs[i] = pos + aux_start - 1\n",
    "                    elif ind == 2:\n",
    "                        locs[i] = aux_loc + aux_start - 1\n",
    "                    i = i + 1\n",
    "\n",
    "    #plt.scatter(locs,x[locs],marker = 'o',color = 'yellow', label = 'After not-peak correction')\n",
    "\n",
    "    # Correction of peaks according to amplitude\n",
    "    len_window = np.round(t*fs)\n",
    "    #print('Window length: ' + str(len_window))\n",
    "    keep = np.empty(0)\n",
    "    first_i = 0\n",
    "    second_i = len_window - 1\n",
    "    while second_i < len(x):\n",
    "        ind1, = np.where(locs >= first_i)\n",
    "        ind2, = np.where(locs <= second_i)\n",
    "        ind = np.intersect1d(ind1, ind2)\n",
    "        win = locs[ind]\n",
    "        if np.median(x[win]) > 0:\n",
    "            th_amp_low = 0.5*np.median(x[win])\n",
    "            th_amp_high = 3*np.median(x[win])\n",
    "        else:\n",
    "            th_amp_low = -3*np.median(x[win])\n",
    "            th_amp_high = 1.5*np.median(x[win])\n",
    "        ind1, = np.where(x[win] >= th_amp_low)\n",
    "        ind2, = np.where(x[win] <= th_amp_high)\n",
    "        aux_keep = np.intersect1d(ind1,ind2)\n",
    "        keep = np.append(keep, aux_keep)\n",
    "\n",
    "        first_i = second_i + 1\n",
    "        second_i = second_i + stride*fs - 1\n",
    "\n",
    "    if len(keep) != 0:\n",
    "        keep = np.unique(keep)\n",
    "        locs = locs[keep.astype(int)]\n",
    "\n",
    "    #plt.scatter(locs,x[locs],marker = 'o',color = 'purple', label = 'After amplitude correction')\n",
    "    #plt.legend()\n",
    "\n",
    "    return locs\n",
    "\n",
    "def find_closest_peak(x, loc, dir_search):\n",
    "    \"\"\"\n",
    "    Finds the closest peak to the initial location in x\n",
    "\n",
    "    Inputs:   x, signal of interest [user defined units]\n",
    "              loc, initial location [number of samples]\n",
    "              dir_search, direction of search ['backward','forward']\n",
    "    Outputs:  pos, location of the first peak detected in specified direction [number of samples]\n",
    "\n",
    "    Developed by:  Elisa Mejía Mejía\n",
    "                   City, University of London\n",
    "    Version:       1.0 -   June, 2022\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pos = -1\n",
    "    if dir_search == 'backward':\n",
    "        i = loc - 2\n",
    "        while i > 0:\n",
    "            if (x[i] > x[i - 1]) and (x[i] > x[i + 1]):\n",
    "                pos = i\n",
    "                i = 0\n",
    "            else:\n",
    "                i = i - 1\n",
    "        if pos == -1:\n",
    "            pos = loc\n",
    "    elif dir_search == 'forward':\n",
    "        i = loc + 1\n",
    "        while i < len(x) - 1:\n",
    "            if (x[i] > x[i - 1]) and (x[i] > x[i + 1]):\n",
    "                pos = i\n",
    "                i = len(x)\n",
    "            else:\n",
    "                i = i + 1\n",
    "        if pos == -1:\n",
    "            pos = loc\n",
    "\n",
    "    return pos\n",
    "\n",
    "def seek_local(x, start, end):\n",
    "    val_min = x[start]\n",
    "    val_max = x[start]\n",
    "\n",
    "    ind_min = start\n",
    "    ind_max = start\n",
    "\n",
    "    for j in range(start, end):\n",
    "        if x[j] > val_max:\n",
    "            val_max = x[j]\n",
    "            ind_max = j\n",
    "        elif x[j] < val_min:\n",
    "            val_min = x[j]\n",
    "            ind_min = j\n",
    "\n",
    "    return val_min, ind_min, val_max, ind_max\n",
    "\n",
    "def heartpy(x, fs, min_ihr, max_ihr, w):\n",
    "    \"\"\"\n",
    "    Detects inter-beat intervals using HeartPy\n",
    "    Citation: van Gent P, Farah H, van Nes N, van Arem B (2019) Heartpy: A novel heart rate algorithm\n",
    "              for the analysis of noisy signals. Transp Res Part F, vol. 66, pp. 368-378. DOI: 10.1016/j.trf.2019.09.015\n",
    "\n",
    "    Inputs:   x, pulsatile signal [user defined units]\n",
    "              fs, sampling rate [Hz]\n",
    "              min_ihr, minimum value of instantaneous heart rate to be accepted [bpm]\n",
    "              max_ihr, maximum value of instantaneous heart rate to be accepted [bpm]\n",
    "              w, length of segments for correction of peaks [s]\n",
    "    Outputs:  ibis, position of the starting points of inter-beat intervals [number of samples]\n",
    "\n",
    "    Developed by:  Elisa Mejía Mejía\n",
    "                   City, University of London\n",
    "    Version:       1.0 -   June, 2022\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Identification of peaks\n",
    "    is_roi = 0\n",
    "    n_rois = 0\n",
    "    pos_pks = np.empty(0).astype(int)\n",
    "    locs = np.empty(0).astype(int)\n",
    "\n",
    "    len_ma = int(np.round(0.75*fs))\n",
    "    #print(len_ma)\n",
    "    sig = np.append(x[0]*np.ones(len_ma), x)\n",
    "    sig = np.append(sig, x[-1]*np.ones(len_ma))\n",
    "\n",
    "    i = len_ma\n",
    "    while i < len(sig) - len_ma:\n",
    "        ma = np.mean(sig[i - len_ma:i + len_ma - 1])\n",
    "        #print(len(sig[i - len_ma:i + len_ma - 1]),ma)\n",
    "\n",
    "        # If it is the beginning of a new ROI:\n",
    "        if is_roi == 0 and sig[i] >= ma:\n",
    "            is_roi = 1\n",
    "            n_rois = n_rois + 1\n",
    "            #print('New ROI ---' + str(n_rois) + ' @ ' + str(i))\n",
    "            # If it is a peak:\n",
    "            if sig[i] >= sig[i - 1] and sig[i] >= sig[i + 1]:\n",
    "                pos_pks = np.append(pos_pks, int(i))\n",
    "                #print('Possible peaks: ' + str(pos_pks))\n",
    "\n",
    "        # If it is part of a ROI which is not over:\n",
    "        elif is_roi == 1 and sig[i] > ma:\n",
    "            #print('Actual ROI ---' + str(n_rois) + ' @ ' + str(i))\n",
    "            # If it is a peak:\n",
    "            if sig[i] >= sig[i - 1] and sig[i] >= sig[i + 1]:\n",
    "                pos_pks = np.append(pos_pks, int(i))\n",
    "                #print('Possible peaks: ' + str(pos_pks))\n",
    "\n",
    "        # If the ROI is over or the end of the signal has been reached:\n",
    "        elif is_roi == 1 and (sig[i] < ma or i == (len(sig) - len_ma)):\n",
    "            #print('End of ROI ---' + str(n_rois) + ' @ ' + str(i) + '. Pos pks: ' + str(pos_pks))\n",
    "            is_roi = 0 # Lowers flag\n",
    "\n",
    "            # If it is the end of the first ROI:\n",
    "            if n_rois == 1:\n",
    "                # If at least one peak has been found:\n",
    "                if len(pos_pks) != 0:\n",
    "                    # Determines the location of the maximum peak:\n",
    "                    max_pk = np.max(sig[pos_pks])\n",
    "                    ind, = np.where(max_pk == np.max(sig[pos_pks]))\n",
    "                    #print('First ROI: (1) Max Peak: ' + str(max_pk) + ', amplitudes: ' + str(sig[pos_pks]) +\n",
    "                    #      ', index: ' + str(int(ind)), ', pk_ind: ' + str(pos_pks[ind]))\n",
    "                    # The maximum peak is added to the list:\n",
    "                    locs = np.append(locs, pos_pks[ind])\n",
    "                    #print('Locations: ' + str(locs))\n",
    "                # If no peak was found:\n",
    "                else:\n",
    "                    # Counter for ROIs is reset to previous value:\n",
    "                    n_rois = n_rois - 1\n",
    "\n",
    "            # If it is the end of the second ROI:\n",
    "            elif n_rois == 2:\n",
    "                # If at least one peak has been found:\n",
    "                if len(pos_pks) != 0:\n",
    "                    # Measures instantantaneous HR of found peaks with respect to the previous peak:\n",
    "                    ihr = 60/((pos_pks - locs[-1])/fs)\n",
    "                    good_ihr, = np.where(ihr <= max_ihr and ihr >= min_ihr)\n",
    "                    #print('Second ROI IHR check: (1) IHR: ' + str(ihr) + ', valid peaks: ' + str(good_ihr) +\n",
    "                    #      ', pos_pks before: ' + str(pos_pks) + ', pos_pks after: ' + str(pos_pks[good_ihr]))\n",
    "                    pos_pks = pos_pks[good_ihr].astype(int)\n",
    "\n",
    "                    # If at least one peak is between HR limits:\n",
    "                    if len(pos_pks) != 0:\n",
    "                        # Determines the location of the maximum peak:\n",
    "                        max_pk = np.max(sig[pos_pks])\n",
    "                        ind, = np.where(max_pk == np.max(sig[pos_pks]))\n",
    "                        #print('Second ROI: (1) Max Peak: ' + str(max_pk) + ', amplitudes: ' + str(sig[pos_pks]) +\n",
    "                        #  ', index: ' + str(int(ind)), ', pk_ind: ' + str(pos_pks[ind]))\n",
    "                        # The maximum peak is added to the list:\n",
    "                        locs = np.append(locs, pos_pks[ind])\n",
    "                        #print('Locations: ' + str(locs))\n",
    "                # If no peak was found:\n",
    "                else:\n",
    "                    # Counter for ROIs is reset to previous value:\n",
    "                    n_rois = n_rois - 1\n",
    "\n",
    "            # If it is the end of the any further ROI:\n",
    "            else:\n",
    "                # If at least one peak has been found:\n",
    "                if len(pos_pks) != 0:\n",
    "                    # Measures instantantaneous HR of found peaks with respect to the previous peak:\n",
    "                    ihr = 60/((pos_pks - locs[-1])/fs)\n",
    "                    good_ihr, = np.where(ihr <= max_ihr and ihr >= min_ihr)\n",
    "                    #print('Third ROI IHR check: (1) IHR: ' + str(ihr) + ', valid peaks: ' + str(good_ihr) +\n",
    "                    #      ', pos_pks before: ' + str(pos_pks) + ', pos_pks after: ' + str(pos_pks[good_ihr]))\n",
    "                    pos_pks = pos_pks[good_ihr].astype(int)\n",
    "\n",
    "                    # If at least one peak is between HR limits:\n",
    "                    if len(pos_pks) != 0:\n",
    "                        # Calculates SDNN with the possible peaks on the ROI:\n",
    "                        sdnn = np.zeros(len(pos_pks))\n",
    "                        for j in range(len(pos_pks)):\n",
    "                            sdnn[j] = np.std(np.append(locs/fs, pos_pks[j]/fs))\n",
    "                        # Determines the new peak as that one with the lowest SDNN:\n",
    "                        min_pk = np.min(sdnn)\n",
    "                        ind, = np.where(min_pk == np.min(sdnn))\n",
    "                        #print('Third ROI: (1) Min SDNN Peak: ' + str(min_pk) + ', amplitudes: ' + str(sig[pos_pks]) +\n",
    "                        #  ', index: ' + str(int(ind)), ', pk_ind: ' + str(pos_pks[ind]))\n",
    "                        locs = np.append(locs, pos_pks[ind])\n",
    "                        #print('Locations: ' + str(locs))\n",
    "                # If no peak was found:\n",
    "                else:\n",
    "                    # Counter for ROIs is reset to previous value:\n",
    "                    n_rois = n_rois - 1\n",
    "\n",
    "            # Resets possible peaks for next ROI:\n",
    "            pos_pks = np.empty(0)\n",
    "\n",
    "        i = i + 1;\n",
    "\n",
    "    locs = locs - len_ma\n",
    "\n",
    "    # Correction of peaks\n",
    "    c_locs = np.empty(0)\n",
    "    n_int = np.floor(len(x)/(w*fs))\n",
    "    for i in range(int(n_int)):\n",
    "        ind1, = np.where(locs >= i*w*fs)\n",
    "        #print('Locs >= ' + str((i)*w*fs) + ': ' + str(locs[ind1]))\n",
    "        ind2, = np.where(locs < (i + 1)*w*fs)\n",
    "        #print('Locs < ' + str((i + 1)*w*fs) + ': ' + str(locs[ind2]))\n",
    "        ind = np.intersect1d(ind1, ind2)\n",
    "        #print('Larger and lower than locs: ' + str(locs[ind]))\n",
    "        int_locs = locs[ind]\n",
    "\n",
    "        if i == 0:\n",
    "            aux_ibis = np.diff(int_locs)\n",
    "        else:\n",
    "            ind, = np.where(locs >= i*w*fs)\n",
    "            last = locs[ind[0] - 1]\n",
    "            aux_ibis = np.diff(np.append(last, int_locs))\n",
    "        avg_ibis = np.mean(aux_ibis)\n",
    "        th = np.append((avg_ibis - 0.3*avg_ibis), (avg_ibis + 0.3*avg_ibis))\n",
    "        ind1, = np.where(aux_ibis > th[0])\n",
    "        #print('Ind1: ' + str(ind1))\n",
    "        ind2, = np.where(aux_ibis < th[1])\n",
    "        #print('Ind2: ' + str(ind2))\n",
    "        ind = np.intersect1d(ind1, ind2)\n",
    "        #print('Ind: ' + str(ind))\n",
    "\n",
    "        c_locs = np.append(c_locs, int_locs[ind]).astype(int)\n",
    "        print(c_locs)\n",
    "\n",
    "    #fig = plt.figure()\n",
    "    #plt.plot(x)\n",
    "    #plt.plot(sig)\n",
    "    #plt.scatter(locs,x[locs],marker = 'o',color = 'red')\n",
    "    #if len(c_locs) != 0:\n",
    "        #plt.scatter(c_locs,x[c_locs],marker = 'o',color = 'blue')\n",
    "\n",
    "    if len(c_locs) != 0:\n",
    "        ibis = c_locs\n",
    "    else:\n",
    "        ibis = locs\n",
    "\n",
    "    return ibis\n",
    "\n",
    "def d2max(x, fs):\n",
    "    \"\"\"\n",
    "    Detects inter-beat intervals using D2Max\n",
    "    Citation: Elgendi M, Norton I, Brearley M, Abbott D, Schuurmans D (2013) Systolic Peak Detection in Acceleration\n",
    "              Photoplethysmograms Measured from Emergency Responders in Tropical Conditions. PLoS ONE, vol. 8, no. 10,\n",
    "              pp. e76585. DOI: 10.1371/journal.pone.0076585\n",
    "\n",
    "    Inputs:   x, pulsatile signal [user defined units]\n",
    "              fs, sampling rate [Hz]\n",
    "    Outputs:  ibis, position of the starting points of inter-beat intervals [number of samples]\n",
    "\n",
    "    Developed by:  Elisa Mejía Mejía\n",
    "                   City, University of London\n",
    "    Version:       1.0 -   June, 2022\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Bandpass filter\n",
    "    if len(x) < 4098:\n",
    "        z_fill = np.zeros(4098 - len(x) + 1)\n",
    "        x_z = np.append(x, z_fill)\n",
    "    sos = sp.butter(10, [0.5, 8], btype = 'bp', analog = False, output = 'sos', fs = fs)\n",
    "    x_f = sp.sosfiltfilt(sos, x_z)\n",
    "\n",
    "    # Signal clipping\n",
    "    ind, = np.where(x_f < 0)\n",
    "    x_c = x_f\n",
    "    x_c[ind] = 0\n",
    "\n",
    "    # Signal squaring\n",
    "    x_s = x_c**2\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(x)\n",
    "    #plt.plot(x_z)\n",
    "    #plt.plot(x_f)\n",
    "    #plt.plot(x_c)\n",
    "    #plt.plot(x_s)\n",
    "\n",
    "    # Blocks of interest\n",
    "    w1 = (111e-3)*fs\n",
    "    w1 = int(2*np.floor(w1/2) + 1)\n",
    "    b = (1/w1)*np.ones(w1)\n",
    "    ma_pk = sp.filtfilt(b,1,x_s)\n",
    "\n",
    "    w2 = (667e-3)*fs\n",
    "    w2 = int(2*np.floor(w2/2) + 1)\n",
    "    b = (1/w2)*np.ones(w1)\n",
    "    ma_bpm = sp.filtfilt(b,1,x_s)\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(x_s/np.max(x_s))\n",
    "    #plt.plot(ma_pk/np.max(ma_pk))\n",
    "    #plt.plot(ma_bpm/np.max(ma_bpm))\n",
    "\n",
    "    # Thresholding\n",
    "    alpha = 0.02*np.mean(ma_pk)\n",
    "    th_1 = ma_bpm + alpha\n",
    "    th_2 = w1\n",
    "    boi = (ma_pk > th_1).astype(int)\n",
    "\n",
    "    blocks_init, = np.where(np.diff(boi) > 0)\n",
    "    blocks_init = blocks_init + 1\n",
    "    blocks_end, = np.where(np.diff(boi) < 0)\n",
    "    blocks_end = blocks_end + 1\n",
    "    if blocks_init[0] > blocks_end[0]:\n",
    "        blocks_init = np.append(1, blocks_init)\n",
    "    if blocks_init[-1] > blocks_end[-1]:\n",
    "        blocks_end = np.append(blocks_end, len(x_s))\n",
    "    #print('Initial locs BOI: ' + str(blocks_init))\n",
    "    #print('Final locs BOI: ' + str(blocks_end))\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(x_s[range(len(x))]/np.max(x_s))\n",
    "    #plt.plot(boi[range(len(x))])\n",
    "\n",
    "    # Search for peaks inside BOIs\n",
    "    len_blks = np.zeros(len(blocks_init))\n",
    "    ibis = np.zeros(len(blocks_init))\n",
    "    for i in range(len(blocks_init)):\n",
    "        ind, = np.where(blocks_end > blocks_init[i])\n",
    "        ind = ind[0]\n",
    "        len_blks[i] = blocks_end[ind] - blocks_init[i]\n",
    "        if len_blks[i] >= th_2:\n",
    "            aux = x[blocks_init[i]:blocks_end[ind]]\n",
    "            if len(aux) != 0:\n",
    "                max_val = np.max(aux)\n",
    "                max_ind, = np.where(max_val == aux)\n",
    "                ibis[i] = max_ind + blocks_init[i] - 1\n",
    "\n",
    "    ind, = np.where(len_blks < th_2)\n",
    "    if len(ind) != 0:\n",
    "        for i in range(len(ind)):\n",
    "            boi[blocks_init[i]:blocks_end[i]] = 0\n",
    "    ind, = np.where(ibis == 0)\n",
    "    ibis = (np.delete(ibis, ind)).astype(int)\n",
    "\n",
    "    #plt.plot(boi[range(len(x))])\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(x)\n",
    "    #plt.scatter(ibis, x[ibis], marker = 'o',color = 'red')\n",
    "\n",
    "    return ibis\n",
    "\n",
    "def upslopes(x):\n",
    "    \"\"\"\n",
    "    Detects inter-beat intervals using Upslopes\n",
    "    Citation: Arguello Prada EJ, Serna Maldonado RD (2018) A novel and low-complexity peak detection algorithm for\n",
    "              heart rate estimation from low-amplitude photoplethysmographic (PPG) signals. J Med Eng Technol, vol. 42,\n",
    "              no. 8, pp. 569-577. DOI: 10.1080/03091902.2019.1572237\n",
    "\n",
    "    Inputs:   x, pulsatile signal [user defined units]\n",
    "    Outputs:  ibis, position of the starting points of inter-beat intervals [number of samples]\n",
    "\n",
    "    Developed by:  Elisa Mejía Mejía\n",
    "                   City, University of London\n",
    "    Version:       1.0 -   June, 2022\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Peak detection\n",
    "    th = 6\n",
    "    pks = np.empty(0)\n",
    "    pos_pk = np.empty(0)\n",
    "    pos_pk_b = 0\n",
    "    n_pos_pk = 0\n",
    "    n_up = 0\n",
    "\n",
    "    for i in range(1, len(x)):\n",
    "        if x[i] > x[i - 1]:\n",
    "            n_up = n_up + 1\n",
    "        else:\n",
    "            if n_up > th:\n",
    "                pos_pk = np.append(pos_pk, i)\n",
    "                pos_pk_b = 1\n",
    "                n_pos_pk = n_pos_pk + 1\n",
    "                n_up_pre = n_up\n",
    "            else:\n",
    "                pos_pk = pos_pk.astype(int)\n",
    "                #print('Possible peaks: ' + str(pos_pk) + ', number of peaks: ' + str(n_pos_pk))\n",
    "                if pos_pk_b == 1:\n",
    "                    if x[i - 1] > x[pos_pk[n_pos_pk - 1]]:\n",
    "                        pos_pk[n_pos_pk - 1] = i - 1\n",
    "                    else:\n",
    "                        pks = np.append(pks, pos_pk[n_pos_pk - 1])\n",
    "                    th = 0.6*n_up_pre\n",
    "                    pos_pk_b = 0\n",
    "            n_up = 0\n",
    "    ibis = pks.astype(int)\n",
    "    #print(ibis)\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(x)\n",
    "    #plt.scatter(ibis, x[ibis], marker = 'o',color = 'red')\n",
    "\n",
    "    return ibis\n",
    "\n",
    "def delineator(x, fs):\n",
    "    \"\"\"\n",
    "    Detects inter-beat intervals using Delineator\n",
    "    Citation: Li BN, Dong MC, Vai MI (2010) On an automatic delineator for arterial blood pressure waveforms. Biomed\n",
    "    Signal Process Control, vol. 5, no. 1, pp. 76-81. DOI: 10.1016/j.bspc.2009.06.002\n",
    "\n",
    "    Inputs:   x, pulsatile signal [user defined units]\n",
    "              fs, sampling rate [Hz]\n",
    "    Outputs:  ibis, position of the starting points of inter-beat intervals [number of samples]\n",
    "\n",
    "    Developed by:  Elisa Mejía Mejía\n",
    "                   City, University of London\n",
    "    Version:       1.0 -   June, 2022\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Lowpass filter\n",
    "    od = 3\n",
    "    sos = sp.butter(od, 25, btype = 'low', analog = False, output = 'sos', fs = fs)\n",
    "    x_f = sp.sosfiltfilt(sos, x)\n",
    "    x_m = 1000*x_f\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(x)\n",
    "    #plt.plot(x_f)\n",
    "    #plt.plot(x_m)\n",
    "\n",
    "    # Moving average\n",
    "    n = 5\n",
    "    b = (1/n)*np.ones(n)\n",
    "    x_ma = sp.filtfilt(b,1,x_m)\n",
    "\n",
    "    # Compute differentials\n",
    "    dif = np.diff(x_ma)\n",
    "    dif = 100*np.append(dif[0], dif)\n",
    "    dif_ma = sp.filtfilt(b,1,dif)\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(x_ma)\n",
    "    #plt.plot(dif_ma)\n",
    "\n",
    "    # Average thresholds in original signal\n",
    "    x_len = len(x)\n",
    "    if x_len > 12*fs:\n",
    "        n = 10\n",
    "    elif x_len > 7*fs:\n",
    "        n = 5\n",
    "    elif x_len > 4*fs:\n",
    "        n = 2\n",
    "    else:\n",
    "        n = 1\n",
    "    #print(n)\n",
    "\n",
    "    max_min = np.empty(0)\n",
    "    if n > 1:\n",
    "        #plt.figure()\n",
    "        #plt.plot(x_ma)\n",
    "        n_int = np.floor(x_len/(n + 2))\n",
    "        #print('Length of intervals: ' + str(n_int))\n",
    "        for j in range(n):\n",
    "            # Searches for max and min in 1 s intervals\n",
    "            amp_min, ind_min, amp_max, ind_max = seek_local(x_ma, int(j*n_int), int(j*n_int + fs))\n",
    "            #plt.scatter(ind_min, amp_min, marker = 'o', color = 'red')\n",
    "            #plt.scatter(ind_max, amp_max, marker = 'o', color = 'green')\n",
    "            max_min = np.append(max_min, (amp_max - amp_min))\n",
    "        max_min_avg = np.mean(max_min)\n",
    "        #print('Local max and min: ' + str(max_min) + ', average amplitude: ' + str(max_min_avg))\n",
    "    else:\n",
    "        amp_min, ind_min , amp_max, ind_max = seek_local(x_ma, int(close_win), int(x_len))\n",
    "        #plt.figure()\n",
    "        #plt.plot(x_ma)\n",
    "        #plt.scatter(ind_min, amp_min, marker = 'o', color = 'red')\n",
    "        #plt.scatter(ind_max, amp_max, marker = 'o', color = 'green')\n",
    "        max_min_avg = amp_max - amp_min\n",
    "        #print('Local max and min: ' + str(max_min) + ', average amplitude: ' + str(max_min_avg))\n",
    "\n",
    "    max_min_lt = 0.4*max_min_avg\n",
    "\n",
    "    # Seek pulse beats by min-max method\n",
    "    step_win = 2*fs       # Window length to look for peaks/onsets\n",
    "    close_win = np.floor(0.1*fs)\n",
    "                          # Value of what is considered too close\n",
    "\n",
    "    pks = np.empty(0)     # Location of peaks\n",
    "    ons = np.empty(0)     # Location of onsets\n",
    "    dic = np.empty(0)     # Location of dicrotic notches\n",
    "\n",
    "    pk_index = -1          # Number of peaks found\n",
    "    on_index = -1          # Number of onsets found\n",
    "    dn_index = -1          # Number of dicrotic notches found\n",
    "\n",
    "    i = int(close_win)    # Initializes counter\n",
    "    while i < x_len:      # Iterates through the signal\n",
    "        #print('i: ' + str(i))\n",
    "        amp_min = x_ma[i] # Gets the initial value for the minimum amplitude\n",
    "        amp_max = x_ma[i] # Gets the initial value for the maximum amplitude\n",
    "\n",
    "        ind = i           # Initializes the temporal location of the index\n",
    "        aux_pks = i       # Initializes the temporal location of the peak\n",
    "        aux_ons = i       # Initializes the temporal location of the onset\n",
    "\n",
    "        # Iterates while ind is lower than the length of the signal\n",
    "        while ind < x_len - 1:\n",
    "            #print('Ind: ' + str(ind))\n",
    "            # Verifies if no peak has been found in 2 seconds\n",
    "            if (ind - i) > step_win:\n",
    "                #print('Peak not found in 2 s')\n",
    "                ind = i   # Refreshes the temporal location of the index\n",
    "                max_min_avg = 0.6*max_min_avg  # Refreshes the threshold for the amplitude\n",
    "                # Verifies if the threshold is lower than the lower limit\n",
    "                if max_min_avg <= max_min_lt:\n",
    "                    max_min_avg = 2.5*max_min_lt # Refreshes the threshold\n",
    "                break\n",
    "\n",
    "            # Verifies if the location is a candidate peak\n",
    "            if (dif_ma[ind - 1]*dif_ma[ind + 1]) <= 0:\n",
    "                #print('There is a candidate peak')\n",
    "                # Determines initial and end points of a window to search for local peaks and onsets\n",
    "                if (ind + 5) < x_len:\n",
    "                    i_stop = ind + 5\n",
    "                else:\n",
    "                    i_stop = x_len - 1\n",
    "                if (ind - 5) >= 0:\n",
    "                    i_start = ind - 5\n",
    "                else:\n",
    "                    i_start = 0\n",
    "\n",
    "                # Checks for artifacts of saturated or signal loss\n",
    "                if (i_stop - ind) >= 5:\n",
    "                    for j in range(ind, i_stop):\n",
    "                        if dif_ma[j] != 0:\n",
    "                            break\n",
    "                    if j == i_stop:\n",
    "                        #print('Artifact')\n",
    "                        break\n",
    "\n",
    "                # Candidate onset\n",
    "                #print('Looking for candidate onsets...')\n",
    "                #plt.figure()\n",
    "                #plt.plot(x_ma)\n",
    "                if dif_ma[i_start] < 0:\n",
    "                    if dif_ma[i_stop] > 0:\n",
    "                        aux_min, ind_min, _, _ = seek_local(x_ma, int(i_start), int(i_stop))\n",
    "                        #plt.scatter(ind_min, aux_min, marker = 'o', color = 'red')\n",
    "                        if np.abs(ind_min - ind) <= 2:\n",
    "                            amp_min = aux_min\n",
    "                            aux_ons = ind_min\n",
    "                #print('Candidate onset: ' + str([ind_min, amp_min]))\n",
    "                # Candidate peak\n",
    "                #print('Looking for candidate peaks...')\n",
    "                if dif_ma[i_start] > 0:\n",
    "                    if dif_ma[i_stop] < 0:\n",
    "                        _, _, aux_max, ind_max = seek_local(x_ma, int(i_start), int(i_stop))\n",
    "                        #plt.scatter(ind_max, aux_max, marker = 'o', color = 'green')\n",
    "                        if np.abs(ind_max - ind) <= 2:\n",
    "                            amp_max = aux_max\n",
    "                            aux_pks = ind_max\n",
    "                #print('Candidate peak: ' + str([ind_max, amp_max]))\n",
    "                # Verifies if the amplitude of the pulse is larger than 0.4 times the mean value:\n",
    "                #print('Pulse amplitude: ' + str(amp_max - amp_min) + ', thresholds: ' +\n",
    "                #      str([0.4*max_min_avg, 2*max_min_avg]))\n",
    "                if (amp_max - amp_min) > 0.4*max_min_avg:\n",
    "                    #print('Expected amplitude of pulse')\n",
    "                    # Verifies if the amplitude of the pulse is lower than 2 times the mean value:\n",
    "                    if (amp_max - amp_min) < 2*max_min_avg:\n",
    "                        #print('Expected duration of pulse')\n",
    "                        if aux_pks > aux_ons:\n",
    "                            #print('Refining onsets...')\n",
    "                            # Refine onsets:\n",
    "                            aux_min = x_ma[aux_ons]\n",
    "                            temp_ons = aux_ons\n",
    "                            for j in range(aux_pks, aux_ons + 1, -1):\n",
    "                                if x_ma[j] < aux_min:\n",
    "                                    aux_min = x_ma[j]\n",
    "                                    temp_ons = j\n",
    "                            amp_min = aux_min\n",
    "                            aux_ons = temp_ons\n",
    "\n",
    "                            # If there is at least one peak found before:\n",
    "                            #print('Number of previous peaks: ' + str(pk_index + 1))\n",
    "                            if pk_index >= 0:\n",
    "                                #print('There were previous peaks')\n",
    "                                #print('Duration of ons to peak interval: ' + str(aux_ons - pks[pk_index]) +\n",
    "                                #     ', threshold: ' + str([3*close_win, step_win]))\n",
    "                                # If the duration of the pulse is too short:\n",
    "                                if (aux_ons - pks[pk_index]) < 3*close_win:\n",
    "                                    #print('Too short interbeat interval')\n",
    "                                    ind = i\n",
    "                                    max_min_avg = 2.5*max_min_lt\n",
    "                                    break\n",
    "                                # If the time difference between consecutive peaks is longer:\n",
    "                                if (aux_pks - pks[pk_index]) > step_win:\n",
    "                                    #print('Too long interbeat interval')\n",
    "                                    pk_index = pk_index - 1\n",
    "                                    on_index = on_index - 1\n",
    "                                    #if dn_index > 0:\n",
    "                                    #    dn_index = dn_index - 1\n",
    "                                # If there are still peaks, add the new peak:\n",
    "                                if pk_index >= 0:\n",
    "                                    #print('There are still previous peaks')\n",
    "                                    pk_index = pk_index + 1\n",
    "                                    on_index = on_index + 1\n",
    "                                    pks = np.append(pks, aux_pks)\n",
    "                                    ons = np.append(ons, aux_ons)\n",
    "                                    #print('Peaks: ' + str(pks))\n",
    "                                    #print('Onsets: ' + str(ons))\n",
    "\n",
    "                                    tf = ons[pk_index] - ons[pk_index - 1]\n",
    "\n",
    "                                    to = np.floor(fs/20)\n",
    "                                    tff = np.floor(0.1*tf)\n",
    "                                    if tff < to:\n",
    "                                        to = tff\n",
    "                                    to = pks[pk_index - 1] + to\n",
    "\n",
    "                                    te = np.floor(fs/20)\n",
    "                                    tff = np.floor(0.5*tf)\n",
    "                                    if tff < te:\n",
    "                                        te = tff\n",
    "                                    te = pks[pk_index - 1] + te\n",
    "\n",
    "                                    #tff = seek_dicrotic(dif_ma[to:te])\n",
    "                                    #if tff == 0:\n",
    "                                    #    tff = te - pks[pk_index - 1]\n",
    "                                    #    tff = np.floor(tff/3)\n",
    "                                    #dn_index = dn_index + 1\n",
    "                                    #dic[dn_index] = to + tff\n",
    "\n",
    "                                    ind = ind + close_win\n",
    "                                    break\n",
    "                            # If it is the first peak:\n",
    "                            if pk_index < 0:\n",
    "                                #print('There were no previous peaks')\n",
    "                                pk_index = pk_index + 1\n",
    "                                on_index = on_index + 1\n",
    "                                pks = np.append(pks, aux_pks)\n",
    "                                ons = np.append(ons, aux_ons)\n",
    "                                #print('Peaks: ' + str(pks))\n",
    "                                #print('Onsets: ' + str(ons))\n",
    "                                ind = ind + close_win\n",
    "                                break\n",
    "\n",
    "            ind = ind + 1\n",
    "        i = int(ind + 1)\n",
    "\n",
    "    if len(pks) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        x_len = len(pks)\n",
    "        temp_p = np.empty(0)\n",
    "        for i in range(x_len):\n",
    "            temp_p = np.append(temp_p, pks[i] - od)\n",
    "        ttk = temp_p[0]\n",
    "        if ttk < 0:\n",
    "            temp_p[0] = 0\n",
    "        pks = temp_p\n",
    "\n",
    "        x_len = len(ons)\n",
    "        temp_o = np.empty(0)\n",
    "        for i in range(x_len):\n",
    "            temp_o = np.append(temp_o, ons[i] - od)\n",
    "        ttk = temp_o[0]\n",
    "        if ttk < 0:\n",
    "            temp_o[0] = 0\n",
    "        ons = temp_o\n",
    "\n",
    "    pks = pks + 5\n",
    "    ibis = pks.astype(int)\n",
    "\n",
    "    return ibis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc36557f",
   "metadata": {},
   "source": [
    "# Fiducial Point Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105808e9",
   "metadata": {},
   "source": [
    "Extracting BP values\n",
    "Obtaining BPs from the ABP signal:\n",
    "    \n",
    "1. This has the advantage that no additional files are required, since all signals are stored in the same file. However, it does involve signal processing to obtain the values from the ABP signal.\n",
    "\n",
    "2. We identify pulse onsets and peaks in the ABP signal to derive reference systolic, diastolic and mean BP values from the ABP signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fiducial_points(x,pks,fs,vis):\n",
    "    \"\"\"\n",
    "    Description: Pulse detection and correction from pulsatile signals\n",
    "    Inputs:  x, array with pulsatile signal [user defined units]\n",
    "             pks, array with the position of the peaks [number of samples]\n",
    "             fs, sampling rate of signal [Hz]\n",
    "             vis, visualisation option [True, False]\n",
    "    Outputs: fidp, dictionary with the positions of several fiducial points for the cardiac cycles [number of samples]\n",
    "    \n",
    "    Fiducial points:  1: Systolic peak (pks)\n",
    "                      2: Onset, as the minimum before the systolic peak (ons)\n",
    "                      3: Onset, using the tangent intersection method (ti) \n",
    "                      4: Diastolic peak (dpk)\n",
    "                      5: Maximum slope (m1d)\n",
    "                      6: a point from second derivative PPG (a2d)\n",
    "                      7: b point from second derivative PPG (b2d)\n",
    "                      8: c point from second derivative PPG (c2d)\n",
    "                      9: d point from second derivative PPG (d2d)\n",
    "                      10: e point from second derivative PPG (e2d)\n",
    "                      11: p1 from the third derivative PPG (p1)    \n",
    "                      12: p2 from the third derivative PPG (p2)\n",
    "    \n",
    "    Libraries: NumPy (as np), SciPy (Signal, as sp), Matplotlib (PyPlot, as plt)\n",
    "    \n",
    "    Version: 1.0 - June 2022\n",
    "    \n",
    "    Developed by: Elisa Mejía-Mejía\n",
    "                   City, University of London\n",
    "    \n",
    "    Edited by: Peter Charlton (see \"Added by PC\")\n",
    "    \n",
    "    \"\"\"    \n",
    "    # First, second and third derivatives\n",
    "    d1x = sp.savgol_filter(x, 9, 5, deriv = 1) \n",
    "    d2x = sp.savgol_filter(x, 9, 5, deriv = 2) \n",
    "    d3x = sp.savgol_filter(x, 9, 5, deriv = 3) \n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.plot(x/np.max(x))\n",
    "    #plt.plot(d1x/np.max(d1x))\n",
    "    #plt.plot(d2x/np.max(d2x))\n",
    "    #plt.plot(d3x/np.max(d3x))\n",
    "    \n",
    "    # Search in time series: Onsets between consecutive peaks\n",
    "    ons = np.empty(0)\n",
    "    for i in range(len(pks) - 1):\n",
    "        start = pks[i]\n",
    "        stop = pks[i + 1]\n",
    "        ibi = x[start:stop]\n",
    "        #plt.figure()\n",
    "        #plt.plot(ibi, color = 'black')\n",
    "        aux_ons, = np.where(ibi == np.min(ibi))\n",
    "        ind_ons = aux_ons.astype(int)\n",
    "        ons = np.append(ons, ind_ons + start)   \n",
    "        #plt.plot(ind_ons, ibi[ind_ons], marker = 'o', color = 'red') \n",
    "    ons = ons.astype(int)\n",
    "    #print('Onsets: ' + str(ons))\n",
    "    #plt.figure()\n",
    "    #plt.plot(x, color = 'black')\n",
    "    #plt.scatter(pks, x[pks], marker = 'o', color = 'red') \n",
    "    #plt.scatter(ons, x[ons], marker = 'o', color = 'blue') \n",
    "    \n",
    "    # Search in time series: Diastolic peak and dicrotic notch between consecutive onsets\n",
    "    dia = np.empty(0)\n",
    "    dic = np.empty(0)\n",
    "    for i in range(len(ons) - 1):\n",
    "        start = ons[i]\n",
    "        stop = ons[i + 1]\n",
    "        ind_pks, = np.intersect1d(np.where(pks < stop), np.where(pks > start))\n",
    "        ind_pks = pks[ind_pks]\n",
    "        ibi_portion = x[ind_pks:stop]\n",
    "        ibi_2d_portion = d2x[ind_pks:stop]\n",
    "        #plt.figure()\n",
    "        #plt.plot(ibi_portion/np.max(ibi_portion))\n",
    "        #plt.plot(ibi_2d_portion/np.max(ibi_2d_portion))\n",
    "        aux_dic, _ = sp.find_peaks(ibi_2d_portion)\n",
    "        aux_dic = aux_dic.astype(int)\n",
    "        aux_dia, _ = sp.find_peaks(-ibi_2d_portion)\n",
    "        aux_dia = aux_dia.astype(int)   \n",
    "        if len(aux_dic) != 0:\n",
    "            ind_max, = np.where(ibi_2d_portion[aux_dic] == np.max(ibi_2d_portion[aux_dic]))\n",
    "            aux_dic_max = aux_dic[ind_max]\n",
    "            if len(aux_dia) != 0:\n",
    "                nearest = aux_dia - aux_dic_max\n",
    "                aux_dic = aux_dic_max\n",
    "                dic = np.append(dic, (aux_dic + ind_pks).astype(int))\n",
    "                #plt.scatter(aux_dic, ibi_portion[aux_dic]/np.max(ibi_portion), marker = 'o')\n",
    "                ind_dia, = np.where(nearest > 0)\n",
    "                aux_dia = aux_dia[ind_dia]\n",
    "                nearest = nearest[ind_dia]\n",
    "                if len(nearest) != 0:\n",
    "                    ind_nearest, = np.where(nearest == np.min(nearest))\n",
    "                    aux_dia = aux_dia[ind_nearest]\n",
    "                    dia = np.append(dia, (aux_dia + ind_pks).astype(int))\n",
    "                    #plt.scatter(aux_dia, ibi_portion[aux_dia]/np.max(ibi_portion), marker = 'o')\n",
    "                    #break\n",
    "            else:\n",
    "                dic = np.append(dic, (aux_dic_max + ind_pks).astype(int))\n",
    "                #plt.scatter(aux_dia, ibi_portion[aux_dia]/np.max(ibi_portion), marker = 'o')     \n",
    "    dia = dia.astype(int)\n",
    "    dic = dic.astype(int)\n",
    "    #plt.scatter(dia, x[dia], marker = 'o', color = 'orange')\n",
    "    #plt.scatter(dic, x[dic], marker = 'o', color = 'green')\n",
    "    \n",
    "    # Search in D1: Maximum slope point\n",
    "    m1d = np.empty(0)\n",
    "    for i in range(len(ons) - 1):\n",
    "        start = ons[i]\n",
    "        stop = ons[i + 1]\n",
    "        ind_pks, = np.intersect1d(np.where(pks < stop), np.where(pks > start))\n",
    "        ind_pks = pks[ind_pks]\n",
    "        ibi_portion = x[start:ind_pks]\n",
    "        ibi_1d_portion = d1x[start:ind_pks]\n",
    "        #plt.figure()\n",
    "        #plt.plot(ibi_portion/np.max(ibi_portion))\n",
    "        #plt.plot(ibi_1d_portion/np.max(ibi_1d_portion))\n",
    "        aux_m1d, _ = sp.find_peaks(ibi_1d_portion)\n",
    "        aux_m1d = aux_m1d.astype(int)  \n",
    "        if len(aux_m1d) != 0:\n",
    "            ind_max, = np.where(ibi_1d_portion[aux_m1d] == np.max(ibi_1d_portion[aux_m1d]))\n",
    "            aux_m1d_max = aux_m1d[ind_max]\n",
    "            if len(aux_m1d_max) > 1:\n",
    "                aux_m1d_max = aux_m1d_max[0]\n",
    "            m1d = np.append(m1d, (aux_m1d_max + start).astype(int))\n",
    "            #plt.scatter(aux_m1d, ibi_portion[aux_dic]/np.max(ibi_portion), marker = 'o')\n",
    "            #break    \n",
    "    m1d = m1d.astype(int)\n",
    "    #plt.scatter(m1d, x[m1d], marker = 'o', color = 'purple')\n",
    "    \n",
    "    # Search in time series: Tangent intersection points\n",
    "    tip = np.empty(0)\n",
    "    for i in range(len(ons) - 1):\n",
    "        start = ons[i]\n",
    "        stop = ons[i + 1]\n",
    "        ibi_portion = x[start:stop]\n",
    "        ibi_1d_portion = d1x[start:stop]\n",
    "        ind_m1d, = np.intersect1d(np.where(m1d < stop), np.where(m1d > start))\n",
    "        ind_m1d = m1d[ind_m1d] - start\n",
    "        #plt.figure()\n",
    "        #plt.plot(ibi_portion/np.max(ibi_portion))\n",
    "        #plt.plot(ibi_1d_portion/np.max(ibi_1d_portion))\n",
    "        #plt.scatter(ind_m1d, ibi_portion[ind_m1d]/np.max(ibi_portion), marker = 'o')\n",
    "        #plt.scatter(ind_m1d, ibi_1d_portion[ind_m1d]/np.max(ibi_1d_portion), marker = 'o')\n",
    "        aux_tip = np.round(((ibi_portion[0] - ibi_portion[ind_m1d])/ibi_1d_portion[ind_m1d]) + ind_m1d)\n",
    "        aux_tip = aux_tip.astype(int)\n",
    "        tip = np.append(tip, (aux_tip + start).astype(int))        \n",
    "        #plt.scatter(aux_tip, ibi_portion[aux_tip]/np.max(ibi_portion), marker = 'o')\n",
    "        #break\n",
    "    tip = tip.astype(int)\n",
    "    #plt.scatter(tip, x[tip], marker = 'o', color = 'aqua')\n",
    "    \n",
    "    # Search in D2: A, B, C, D and E points\n",
    "    a2d = np.empty(0)\n",
    "    b2d = np.empty(0)\n",
    "    c2d = np.empty(0)\n",
    "    d2d = np.empty(0)\n",
    "    e2d = np.empty(0)\n",
    "    for i in range(len(ons) - 1):\n",
    "        start = ons[i]\n",
    "        stop = ons[i + 1]\n",
    "        ibi_portion = x[start:stop]\n",
    "        ibi_1d_portion = d1x[start:stop]\n",
    "        ibi_2d_portion = d2x[start:stop]\n",
    "        ind_m1d = np.intersect1d(np.where(m1d > start),np.where(m1d < stop))\n",
    "        ind_m1d = m1d[ind_m1d]\n",
    "        #plt.figure()\n",
    "        #plt.plot(ibi_portion/np.max(ibi_portion))\n",
    "        #plt.plot(ibi_1d_portion/np.max(ibi_1d_portion))\n",
    "        #plt.plot(ibi_2d_portion/np.max(ibi_2d_portion))\n",
    "        aux_m2d_pks, _ = sp.find_peaks(ibi_2d_portion)\n",
    "        aux_m2d_ons, _ = sp.find_peaks(-ibi_2d_portion)\n",
    "        # a point:\n",
    "        ind_a, = np.where(ibi_2d_portion[aux_m2d_pks] == np.max(ibi_2d_portion[aux_m2d_pks]))\n",
    "        ind_a = aux_m2d_pks[ind_a]\n",
    "        if (ind_a < ind_m1d):\n",
    "            a2d = np.append(a2d, ind_a + start)\n",
    "            #plt.scatter(ind_a, ibi_2d_portion[ind_a]/np.max(ibi_2d_portion), marker = 'o')\n",
    "            # b point:\n",
    "            ind_b = np.where(ibi_2d_portion[aux_m2d_ons] == np.min(ibi_2d_portion[aux_m2d_ons]))\n",
    "            ind_b = aux_m2d_ons[ind_b]\n",
    "            if (ind_b > ind_a) and (ind_b < len(ibi_2d_portion)):\n",
    "                b2d = np.append(b2d, ind_b + start)\n",
    "                #plt.scatter(ind_b, ibi_2d_portion[ind_b]/np.max(ibi_2d_portion), marker = 'o')\n",
    "        # e point:\n",
    "        ind_e, = np.where(aux_m2d_pks > ind_m1d - start)\n",
    "        aux_m2d_pks = aux_m2d_pks[ind_e]\n",
    "        ind_e, = np.where(aux_m2d_pks < 0.6*len(ibi_2d_portion))\n",
    "        ind_e = aux_m2d_pks[ind_e]\n",
    "        if len(ind_e) >= 1:\n",
    "            if len(ind_e) >= 2:\n",
    "                ind_e = ind_e[1]\n",
    "            e2d = np.append(e2d, ind_e + start)\n",
    "            #plt.scatter(ind_e, ibi_2d_portion[ind_e]/np.max(ibi_2d_portion), marker = 'o')\n",
    "            # c point:\n",
    "            ind_c, = np.where(aux_m2d_pks < ind_e)\n",
    "            if len(ind_c) != 0:\n",
    "                ind_c_aux = aux_m2d_pks[ind_c]\n",
    "                ind_c, = np.where(ibi_2d_portion[ind_c_aux] == np.max(ibi_2d_portion[ind_c_aux]))\n",
    "                ind_c = ind_c_aux[ind_c]\n",
    "                if len(ind_c) != 0:\n",
    "                    c2d = np.append(c2d, ind_c + start)\n",
    "                    #plt.scatter(ind_c, ibi_2d_portion[ind_c]/np.max(ibi_2d_portion), marker = 'o')\n",
    "            else:\n",
    "                aux_m1d_ons, _ = sp.find_peaks(-ibi_1d_portion)\n",
    "                ind_c, = np.where(aux_m1d_ons < ind_e)\n",
    "                ind_c_aux = aux_m1d_ons[ind_c]\n",
    "                if len(ind_c) != 0:\n",
    "                    ind_c, = np.where(ind_c_aux > ind_b)\n",
    "                    ind_c = ind_c_aux[ind_c]\n",
    "                    if len(ind_c) > 1:\n",
    "                        ind_c = ind_c[0]\n",
    "                    c2d = np.append(c2d, ind_c + start)\n",
    "                    #plt.scatter(ind_c, ibi_2d_portion[ind_c]/np.max(ibi_2d_portion), marker = 'o')\n",
    "            # d point:\n",
    "            if len(ind_c) != 0:\n",
    "                ind_d = np.intersect1d(np.where(aux_m2d_ons < ind_e), np.where(aux_m2d_ons > ind_c))\n",
    "                if len(ind_d) != 0:\n",
    "                    ind_d_aux = aux_m2d_ons[ind_d]\n",
    "                    ind_d, = np.where(ibi_2d_portion[ind_d_aux] == np.min(ibi_2d_portion[ind_d_aux]))\n",
    "                    ind_d = ind_d_aux[ind_d]\n",
    "                    if len(ind_d) != 0:\n",
    "                        d2d = np.append(d2d, ind_d + start)\n",
    "                        #plt.scatter(ind_d, ibi_2d_portion[ind_d]/np.max(ibi_2d_portion), marker = 'o')                \n",
    "                else:\n",
    "                    ind_d = ind_c\n",
    "                    d2d = np.append(d2d, ind_d + start)\n",
    "                    #plt.scatter(ind_d, ibi_2d_portion[ind_d]/np.max(ibi_2d_portion), marker = 'o')\n",
    "    a2d = a2d.astype(int)\n",
    "    b2d = b2d.astype(int)\n",
    "    c2d = c2d.astype(int)\n",
    "    d2d = d2d.astype(int)\n",
    "    e2d = e2d.astype(int)\n",
    "    #plt.figure()\n",
    "    #plt.plot(d2x, color = 'black')\n",
    "    #plt.scatter(a2d, d2x[a2d], marker = 'o', color = 'red') \n",
    "    #plt.scatter(b2d, d2x[b2d], marker = 'o', color = 'blue')\n",
    "    #plt.scatter(c2d, d2x[c2d], marker = 'o', color = 'green')\n",
    "    #plt.scatter(d2d, d2x[d2d], marker = 'o', color = 'orange')\n",
    "    #plt.scatter(e2d, d2x[e2d], marker = 'o', color = 'purple')\n",
    "    \n",
    "    # Search in D3: P1 and P2 points\n",
    "    p1p = np.empty(0)\n",
    "    p2p = np.empty(0)\n",
    "    for i in range(len(ons) - 1):\n",
    "        start = ons[i]\n",
    "        stop = ons[i + 1]\n",
    "        ibi_portion = x[start:stop]\n",
    "        ibi_1d_portion = d1x[start:stop]\n",
    "        ibi_2d_portion = d2x[start:stop]\n",
    "        ibi_3d_portion = d3x[start:stop]\n",
    "        ind_b = np.intersect1d(np.where(b2d > start),np.where(b2d < stop))\n",
    "        ind_b = b2d[ind_b]\n",
    "        ind_c = np.intersect1d(np.where(c2d > start),np.where(c2d < stop))\n",
    "        ind_c = c2d[ind_c]\n",
    "        ind_d = np.intersect1d(np.where(d2d > start),np.where(d2d < stop))\n",
    "        ind_d = d2d[ind_d]\n",
    "        ind_dic = np.intersect1d(np.where(dic > start),np.where(dic < stop))\n",
    "        ind_dic = dic[ind_dic]\n",
    "        #plt.figure()\n",
    "        #plt.plot(ibi_portion/np.max(ibi_portion))\n",
    "        #plt.plot(ibi_1d_portion/np.max(ibi_1d_portion))\n",
    "        #plt.plot(ibi_2d_portion/np.max(ibi_2d_portion))\n",
    "        #plt.plot(ibi_3d_portion/np.max(ibi_3d_portion))\n",
    "        #plt.scatter(ind_b - start, ibi_3d_portion[ind_b - start]/np.max(ibi_3d_portion), marker = 'o')\n",
    "        #plt.scatter(ind_c - start, ibi_3d_portion[ind_c - start]/np.max(ibi_3d_portion), marker = 'o')\n",
    "        #plt.scatter(ind_d - start, ibi_3d_portion[ind_d - start]/np.max(ibi_3d_portion), marker = 'o')\n",
    "        #plt.scatter(ind_dic - start, ibi_3d_portion[ind_dic - start]/np.max(ibi_3d_portion), marker = 'o')\n",
    "        aux_p3d_pks, _ = sp.find_peaks(ibi_3d_portion)\n",
    "        aux_p3d_ons, _ = sp.find_peaks(-ibi_3d_portion)\n",
    "        # P1:\n",
    "        if (len(aux_p3d_pks) != 0 and len(ind_b) != 0):\n",
    "            ind_p1, = np.where(aux_p3d_pks > ind_b - start)\n",
    "            if len(ind_p1) != 0:\n",
    "                ind_p1 = aux_p3d_pks[ind_p1[0]]\n",
    "                p1p = np.append(p1p, ind_p1 + start)\n",
    "                #plt.scatter(ind_p1, ibi_3d_portion[ind_p1]/np.max(ibi_3d_portion), marker = 'o')\n",
    "        # P2:\n",
    "        if (len(aux_p3d_ons) != 0 and len(ind_c) != 0 and len(ind_d) != 0):\n",
    "            if ind_c == ind_d:\n",
    "                ind_p2, = np.where(aux_p3d_ons > ind_d - start)\n",
    "                ind_p2 = aux_p3d_ons[ind_p2[0]]\n",
    "            else:\n",
    "                ind_p2, = np.where(aux_p3d_ons < ind_d - start)\n",
    "                ind_p2 = aux_p3d_ons[ind_p2[-1]]\n",
    "            if len(ind_dic) != 0:\n",
    "                aux_x_pks, _ = sp.find_peaks(ibi_portion)\n",
    "                if ind_p2 > ind_dic - start:\n",
    "                    ind_between = np.intersect1d(np.where(aux_x_pks < ind_p2), np.where(aux_x_pks > ind_dic - start))\n",
    "                else:\n",
    "                    ind_between = np.intersect1d(np.where(aux_x_pks > ind_p2), np.where(aux_x_pks < ind_dic - start))\n",
    "                if len(ind_between) != 0:\n",
    "                    ind_p2 = aux_x_pks[ind_between[0]]\n",
    "            p2p = np.append(p2p, ind_p2 + start)\n",
    "            #plt.scatter(ind_p2, ibi_3d_portion[ind_p2]/np.max(ibi_3d_portion), marker = 'o')\n",
    "    p1p = p1p.astype(int)\n",
    "    p2p = p2p.astype(int)\n",
    "    #plt.figure()\n",
    "    #plt.plot(d3x, color = 'black')\n",
    "    #plt.scatter(p1p, d3x[p1p], marker = 'o', color = 'green') \n",
    "    #plt.scatter(p2p, d3x[p2p], marker = 'o', color = 'orange')\n",
    "    \n",
    "    # Added by PC: Magnitudes of second derivative points\n",
    "    bmag2d = np.zeros(len(b2d))\n",
    "    cmag2d = np.zeros(len(b2d))\n",
    "    dmag2d = np.zeros(len(b2d))\n",
    "    emag2d = np.zeros(len(b2d))\n",
    "    for beat_no in range(0,len(d2d)):\n",
    "        bmag2d[beat_no] = d2x[b2d[beat_no]]/d2x[a2d[beat_no]]\n",
    "        cmag2d[beat_no] = d2x[c2d[beat_no]]/d2x[a2d[beat_no]]\n",
    "        dmag2d[beat_no] = d2x[d2d[beat_no]]/d2x[a2d[beat_no]]        \n",
    "        emag2d[beat_no] = d2x[e2d[beat_no]]/d2x[a2d[beat_no]]    \n",
    "        \n",
    "     # Added by PC: Refine the list of fiducial points to only include those corresponding to beats for which a full set of points is available\n",
    "    off = ons[1:]\n",
    "    ons = ons[:-1]\n",
    "    if pks[0] < ons[0]:\n",
    "        pks = pks[1:]\n",
    "    if pks[-1] > off[-1]:\n",
    "        pks = pks[:-1]\n",
    "    \n",
    "    # Visualise results\n",
    "    if vis == True:\n",
    "        fig, (ax1,ax2,ax3,ax4) = plt.subplots(4, 1, sharex = True, sharey = False, figsize=(10,10))\n",
    "        fig.suptitle('Fiducial points') \n",
    "\n",
    "        ax1.plot(x, color = 'black')\n",
    "        ax1.scatter(pks, x[pks.astype(int)], color = 'orange', label = 'pks')\n",
    "        ax1.scatter(ons, x[ons.astype(int)], color = 'green', label = 'ons')\n",
    "        ax1.scatter(off, x[off.astype(int)], marker = '*', color = 'green', label = 'off')\n",
    "        ax1.scatter(dia, x[dia.astype(int)], color = 'yellow', label = 'dia')\n",
    "        ax1.scatter(dic, x[dic.astype(int)], color = 'blue', label = 'dic')\n",
    "        ax1.scatter(tip, x[tip.astype(int)], color = 'purple', label = 'dic')\n",
    "        ax1.legend()\n",
    "        ax1.set_ylabel('x')\n",
    "\n",
    "        ax2.plot(d1x, color = 'black')\n",
    "        ax2.scatter(m1d, d1x[m1d.astype(int)], color = 'orange', label = 'm1d')\n",
    "        ax2.legend()\n",
    "        ax2.set_ylabel('d1x')\n",
    "\n",
    "        ax3.plot(d2x, color = 'black')\n",
    "        ax3.scatter(a2d, d2x[a2d.astype(int)], color = 'orange', label = 'a')\n",
    "        ax3.scatter(b2d, d2x[b2d.astype(int)], color = 'green', label = 'b')\n",
    "        ax3.scatter(c2d, d2x[c2d.astype(int)], color = 'yellow', label = 'c')\n",
    "        ax3.scatter(d2d, d2x[d2d.astype(int)], color = 'blue', label = 'd')\n",
    "        ax3.scatter(e2d, d2x[e2d.astype(int)], color = 'purple', label = 'e')\n",
    "        ax3.legend()\n",
    "        ax3.set_ylabel('d2x')\n",
    "\n",
    "        ax4.plot(d3x, color = 'black')\n",
    "        ax4.scatter(p1p, d3x[p1p.astype(int)], color = 'orange', label = 'p1')\n",
    "        ax4.scatter(p2p, d3x[p2p.astype(int)], color = 'green', label = 'p2')\n",
    "        ax4.legend()\n",
    "        ax4.set_ylabel('d3x')\n",
    "\n",
    "        plt.subplots_adjust(left = 0.1,\n",
    "                            bottom = 0.1, \n",
    "                            right = 0.9, \n",
    "                            top = 0.9, \n",
    "                            wspace = 0.4, \n",
    "                            hspace = 0.4)\n",
    "        \n",
    "    # Creation of dictionary\n",
    "    fidp = {'pks': pks.astype(int),\n",
    "            'ons': ons.astype(int),\n",
    "            'off': off.astype(int),  # Added by PC\n",
    "            'tip': tip.astype(int),\n",
    "            'dia': dia.astype(int),\n",
    "            'dic': dic.astype(int),\n",
    "            'm1d': m1d.astype(int),\n",
    "            'a2d': a2d.astype(int),\n",
    "            'b2d': b2d.astype(int),\n",
    "            'c2d': c2d.astype(int),\n",
    "            'd2d': d2d.astype(int),\n",
    "            'e2d': e2d.astype(int),\n",
    "            'bmag2d': bmag2d,\n",
    "            'cmag2d': cmag2d,\n",
    "            'dmag2d': dmag2d,\n",
    "            'emag2d': emag2d,\n",
    "            'p1p': p1p.astype(int),\n",
    "            'p2p': p2p.astype(int)\n",
    "            }\n",
    "    \n",
    "    return fidp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f709c56e",
   "metadata": {},
   "source": [
    "# Pulse Wave Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the MIMIC-IV Waveform Database on PhysioNet\n",
    "database_name = 'mimic4wdb/0.1.0'\n",
    "\n",
    "# Segment for analysis\n",
    "segment_names = ['83404654_0005', '82924339_0007', '84248019_0005', '82439920_0004', '82800131_0002', '84304393_0001', '89464742_0001', '88958796_0004', '88995377_0001', '85230771_0004', '86643930_0004', '81250824_0005', '87706224_0003', '83058614_0005', '82803505_0017', '88574629_0001', '87867111_0012', '84560969_0001', '87562386_0001', '88685937_0001', '86120311_0001', '89866183_0014', '89068160_0002', '86380383_0001', '85078610_0008', '87702634_0007', '84686667_0002', '84802706_0002', '81811182_0004', '84421559_0005', '88221516_0007', '80057524_0005', '84209926_0018', '83959636_0010', '89989722_0016', '89225487_0007', '84391267_0001', '80889556_0002', '85250558_0011', '84567505_0005', '85814172_0007', '88884866_0005', '80497954_0012', '80666640_0014', '84939605_0004', '82141753_0018', '86874920_0014', '84505262_0010', '86288257_0001', '89699401_0001', '88537698_0013', '83958172_0001']\n",
    "segment_dirs = ['mimic4wdb/0.1.0/waves/p100/p10020306/83404654', 'mimic4wdb/0.1.0/waves/p101/p10126957/82924339', 'mimic4wdb/0.1.0/waves/p102/p10209410/84248019', 'mimic4wdb/0.1.0/waves/p109/p10952189/82439920', 'mimic4wdb/0.1.0/waves/p111/p11109975/82800131', 'mimic4wdb/0.1.0/waves/p113/p11392990/84304393', 'mimic4wdb/0.1.0/waves/p121/p12168037/89464742', 'mimic4wdb/0.1.0/waves/p121/p12173569/88958796', 'mimic4wdb/0.1.0/waves/p121/p12188288/88995377', 'mimic4wdb/0.1.0/waves/p128/p12872596/85230771', 'mimic4wdb/0.1.0/waves/p129/p12933208/86643930', 'mimic4wdb/0.1.0/waves/p130/p13016481/81250824', 'mimic4wdb/0.1.0/waves/p132/p13240081/87706224', 'mimic4wdb/0.1.0/waves/p136/p13624686/83058614', 'mimic4wdb/0.1.0/waves/p137/p13791821/82803505', 'mimic4wdb/0.1.0/waves/p141/p14191565/88574629', 'mimic4wdb/0.1.0/waves/p142/p14285792/87867111', 'mimic4wdb/0.1.0/waves/p143/p14356077/84560969', 'mimic4wdb/0.1.0/waves/p143/p14363499/87562386', 'mimic4wdb/0.1.0/waves/p146/p14695840/88685937', 'mimic4wdb/0.1.0/waves/p149/p14931547/86120311', 'mimic4wdb/0.1.0/waves/p151/p15174162/89866183', 'mimic4wdb/0.1.0/waves/p153/p15312343/89068160', 'mimic4wdb/0.1.0/waves/p153/p15342703/86380383', 'mimic4wdb/0.1.0/waves/p155/p15552902/85078610', 'mimic4wdb/0.1.0/waves/p156/p15649186/87702634', 'mimic4wdb/0.1.0/waves/p158/p15857793/84686667', 'mimic4wdb/0.1.0/waves/p158/p15865327/84802706', 'mimic4wdb/0.1.0/waves/p158/p15896656/81811182', 'mimic4wdb/0.1.0/waves/p159/p15920699/84421559', 'mimic4wdb/0.1.0/waves/p160/p16034243/88221516', 'mimic4wdb/0.1.0/waves/p165/p16566444/80057524', 'mimic4wdb/0.1.0/waves/p166/p16644640/84209926', 'mimic4wdb/0.1.0/waves/p167/p16709726/83959636', 'mimic4wdb/0.1.0/waves/p167/p16715341/89989722', 'mimic4wdb/0.1.0/waves/p168/p16818396/89225487', 'mimic4wdb/0.1.0/waves/p170/p17032851/84391267', 'mimic4wdb/0.1.0/waves/p172/p17229504/80889556', 'mimic4wdb/0.1.0/waves/p173/p17301721/85250558', 'mimic4wdb/0.1.0/waves/p173/p17325001/84567505', 'mimic4wdb/0.1.0/waves/p174/p17490822/85814172', 'mimic4wdb/0.1.0/waves/p177/p17738824/88884866', 'mimic4wdb/0.1.0/waves/p177/p17744715/80497954', 'mimic4wdb/0.1.0/waves/p179/p17957832/80666640', 'mimic4wdb/0.1.0/waves/p180/p18080257/84939605', 'mimic4wdb/0.1.0/waves/p181/p18109577/82141753', 'mimic4wdb/0.1.0/waves/p183/p18324626/86874920', 'mimic4wdb/0.1.0/waves/p187/p18742074/84505262', 'mimic4wdb/0.1.0/waves/p188/p18824975/86288257', 'mimic4wdb/0.1.0/waves/p191/p19126489/89699401', 'mimic4wdb/0.1.0/waves/p193/p19313794/88537698', 'mimic4wdb/0.1.0/waves/p196/p19619764/83958172']\n",
    "\n",
    "# 3 and 8 are helpful\n",
    "rel_segment_no = 3\n",
    "rel_segment_name = segment_names[rel_segment_no]\n",
    "rel_segment_dir = segment_dirs[rel_segment_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time since the start of the segment at which to begin extracting data\n",
    "start_seconds = 100\n",
    "n_seconds_to_load = 20\n",
    "\n",
    "segment_metadata = wfdb.rdheader(record_name=rel_segment_name, pn_dir=rel_segment_dir) \n",
    "print(f\"Metadata loaded from segment: {rel_segment_name}\")\n",
    "\n",
    "fs = round(segment_metadata.fs)\n",
    "sampfrom = fs*start_seconds\n",
    "sampto = fs * (start_seconds + n_seconds_to_load)\n",
    "segment_data = wfdb.rdrecord(record_name=rel_segment_name,\n",
    "                             sampfrom=sampfrom,\n",
    "                             sampto=sampto,\n",
    "                             pn_dir=rel_segment_dir) \n",
    "\n",
    "print(\"{} seconds of data extracted from: {}\".format(n_seconds_to_load,\n",
    "                                                     rel_segment_name))\n",
    "\n",
    "ppg_col = []\n",
    "for sig_no in range(0, len(segment_data.sig_name)):\n",
    "    if \"Pleth\" in segment_data.sig_name[sig_no]:\n",
    "        ppg_col = sig_no\n",
    "\n",
    "ppg = segment_data.p_signal[:, ppg_col]\n",
    "fs = segment_data.fs\n",
    "\n",
    "print(f\"Extracted the PPG signal from column {ppg_col} of the matrix of waveform data at {fs:.1f} Hz.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda21b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package\n",
    "import scipy.signal as sp\n",
    "\n",
    "# filter cut-offs, hertz\n",
    "lpf_cutoff = 0.7\n",
    "hpf_cutoff = 10\n",
    "\n",
    "# create filter\n",
    "sos_filter = sp.butter(10, [lpf_cutoff, hpf_cutoff],\n",
    "                       btype = 'bp',\n",
    "                       analog = False,\n",
    "                       output = 'sos',\n",
    "                       fs = segment_data.fs)\n",
    "\n",
    "w, h = sp.sosfreqz(sos_filter, 2000, fs = fs)\n",
    "\n",
    "# filter PPG\n",
    "ppg_filt = sp.sosfiltfilt(sos_filter, ppg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf54b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fs = 125\n",
    "alg = 'd2max'\n",
    "ibis = pulse_detect(ppg_filt, temp_fs, 5, alg)\n",
    "\n",
    "print(f\"Detected {len(ibis)} beats in the PPG signal using the {alg} algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0257e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1,\n",
    "                          sharex = False,\n",
    "                          sharey = False,\n",
    "                          figsize = (8,8))\n",
    "\n",
    "fig.suptitle('IBIs detection') \n",
    "\n",
    "t = np.arange(0,len(ppg_filt)/fs,1.0/fs)\n",
    "\n",
    "ax1.plot(t, ppg_filt, color = 'black')\n",
    "ax1.scatter(t[0] + ibis/fs, ppg_filt[ibis], color = 'orange', marker = 'o')\n",
    "ax1.set_ylabel('PPG [V]')\n",
    "ax1.set_title(alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29421f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fidp = fiducial_points(ppg_filt, ibis, fs, vis = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35fb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(fidp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca38b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Indices of dicrotic notches:\")\n",
    "print(fidp[\"dic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441db7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t = np.zeros(len(fidp[\"dia\"]))\n",
    "for beat_no in range(len(fidp[\"dia\"])):\n",
    "    delta_t[beat_no] = (fidp[\"dia\"][beat_no]-fidp[\"pks\"][beat_no])/fs\n",
    "print(\"Values of Delta T:\")\n",
    "print(delta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40857350",
   "metadata": {},
   "outputs": [],
   "source": [
    "agi = np.zeros(len(fidp[\"dia\"]))\n",
    "for beat_no in range(len(fidp[\"dia\"])):\n",
    "    agi[beat_no] = (fidp[\"bmag2d\"][beat_no]-fidp[\"cmag2d\"][beat_no]-fidp[\"dmag2d\"][beat_no]-fidp[\"emag2d\"][beat_no])/fs\n",
    "print(\"Values of Aging Index:\")\n",
    "print(agi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc75371",
   "metadata": {},
   "source": [
    "# Create DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5834e9f0",
   "metadata": {},
   "source": [
    "### Beat detection setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1954f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracting BP values\n",
    "Obtaining BPs from the ABP signal:\n",
    "This has the advantage that no additional files are required, since all signals are stored in the same file. However, it does involve signal processing to obtain the values from the ABP signal.\n",
    "\n",
    "We identify pulse onsets and peaks in the ABP signal to derive reference systolic, diastolic and mean BP values from the ABP signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8933067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment for analysis\n",
    "\n",
    "\n",
    "segment_names = ['83404654_0005', '82924339_0007', '84248019_0005', '82439920_0004', '82800131_0002', '84304393_0001', '89464742_0001', '88958796_0004', '88995377_0001', '85230771_0004', '86643930_0004', '81250824_0005', '87706224_0003', '83058614_0005', '82803505_0017', '88574629_0001', '87867111_0012', '84560969_0001', '87562386_0001', '88685937_0001', '86120311_0001', '89866183_0014', '89068160_0002', '86380383_0001', '85078610_0008', '87702634_0007', '84686667_0002', '84802706_0002', '81811182_0004', '84421559_0005', '88221516_0007', '80057524_0005', '84209926_0018', '83959636_0010', '89989722_0016', '89225487_0007', '84391267_0001', '80889556_0002', '85250558_0011', '84567505_0005', '85814172_0007', '88884866_0005', '80497954_0012', '80666640_0014', '82141753_0018', '86874920_0014', '84505262_0010', '86288257_0001', '89699401_0001', '88537698_0013', '83958172_0001']\n",
    "segment_dirs = ['mimic4wdb/0.1.0/waves/p100/p10020306/83404654', 'mimic4wdb/0.1.0/waves/p101/p10126957/82924339', 'mimic4wdb/0.1.0/waves/p102/p10209410/84248019', 'mimic4wdb/0.1.0/waves/p109/p10952189/82439920', 'mimic4wdb/0.1.0/waves/p111/p11109975/82800131', 'mimic4wdb/0.1.0/waves/p113/p11392990/84304393', 'mimic4wdb/0.1.0/waves/p121/p12168037/89464742', 'mimic4wdb/0.1.0/waves/p121/p12173569/88958796', 'mimic4wdb/0.1.0/waves/p121/p12188288/88995377', 'mimic4wdb/0.1.0/waves/p128/p12872596/85230771', 'mimic4wdb/0.1.0/waves/p129/p12933208/86643930', 'mimic4wdb/0.1.0/waves/p130/p13016481/81250824', 'mimic4wdb/0.1.0/waves/p132/p13240081/87706224', 'mimic4wdb/0.1.0/waves/p136/p13624686/83058614', 'mimic4wdb/0.1.0/waves/p137/p13791821/82803505', 'mimic4wdb/0.1.0/waves/p141/p14191565/88574629', 'mimic4wdb/0.1.0/waves/p142/p14285792/87867111', 'mimic4wdb/0.1.0/waves/p143/p14356077/84560969', 'mimic4wdb/0.1.0/waves/p143/p14363499/87562386', 'mimic4wdb/0.1.0/waves/p146/p14695840/88685937', 'mimic4wdb/0.1.0/waves/p149/p14931547/86120311', 'mimic4wdb/0.1.0/waves/p151/p15174162/89866183', 'mimic4wdb/0.1.0/waves/p153/p15312343/89068160', 'mimic4wdb/0.1.0/waves/p153/p15342703/86380383', 'mimic4wdb/0.1.0/waves/p155/p15552902/85078610', 'mimic4wdb/0.1.0/waves/p156/p15649186/87702634', 'mimic4wdb/0.1.0/waves/p158/p15857793/84686667', 'mimic4wdb/0.1.0/waves/p158/p15865327/84802706', 'mimic4wdb/0.1.0/waves/p158/p15896656/81811182', 'mimic4wdb/0.1.0/waves/p159/p15920699/84421559', 'mimic4wdb/0.1.0/waves/p160/p16034243/88221516', 'mimic4wdb/0.1.0/waves/p165/p16566444/80057524', 'mimic4wdb/0.1.0/waves/p166/p16644640/84209926', 'mimic4wdb/0.1.0/waves/p167/p16709726/83959636', 'mimic4wdb/0.1.0/waves/p167/p16715341/89989722', 'mimic4wdb/0.1.0/waves/p168/p16818396/89225487', 'mimic4wdb/0.1.0/waves/p170/p17032851/84391267', 'mimic4wdb/0.1.0/waves/p172/p17229504/80889556', 'mimic4wdb/0.1.0/waves/p173/p17301721/85250558', 'mimic4wdb/0.1.0/waves/p173/p17325001/84567505', 'mimic4wdb/0.1.0/waves/p174/p17490822/85814172', 'mimic4wdb/0.1.0/waves/p177/p17738824/88884866', 'mimic4wdb/0.1.0/waves/p177/p17744715/80497954', 'mimic4wdb/0.1.0/waves/p179/p17957832/80666640', 'mimic4wdb/0.1.0/waves/p181/p18109577/82141753', 'mimic4wdb/0.1.0/waves/p183/p18324626/86874920', 'mimic4wdb/0.1.0/waves/p187/p18742074/84505262', 'mimic4wdb/0.1.0/waves/p188/p18824975/86288257', 'mimic4wdb/0.1.0/waves/p191/p19126489/89699401', 'mimic4wdb/0.1.0/waves/p193/p19313794/88537698', 'mimic4wdb/0.1.0/waves/p196/p19619764/83958172']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8df760",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel_segment_no in range(51):\n",
    "    rel_segment_name = segment_names[rel_segment_no]\n",
    "    rel_segment_dir = segment_dirs[rel_segment_no]\n",
    "    # time since the start of the segment at which to begin extracting data\n",
    "    start_seconds = 100\n",
    "    no_seconds_to_load = 20\n",
    "    \n",
    "    segment_metadata = wfdb.rdheader(record_name=rel_segment_name, pn_dir=rel_segment_dir) \n",
    "    print(f\"Metadata loaded from segment: {rel_segment_name}\")\n",
    "\n",
    "    fs = round(segment_metadata.fs)\n",
    "    sampfrom = fs*start_seconds\n",
    "    sampto = fs*(start_seconds+no_seconds_to_load)\n",
    "\n",
    "    segment_data = wfdb.rdrecord(record_name=rel_segment_name,\n",
    "                             sampfrom=sampfrom,\n",
    "                             sampto=sampto,\n",
    "                             pn_dir=rel_segment_dir)\n",
    "\n",
    "    print(f\"{no_seconds_to_load} seconds of data extracted from: {rel_segment_name}\")\n",
    "    abp_col = []\n",
    "    ppg_col = []\n",
    "\n",
    "    for sig_no in range(0,len(segment_data.sig_name)):\n",
    "        if \"ABP\" in segment_data.sig_name[sig_no]:\n",
    "            abp_col = sig_no\n",
    "        if \"Pleth\" in segment_data.sig_name[sig_no]:\n",
    "            ppg_col = sig_no\n",
    "\n",
    "    abp = segment_data.p_signal[:,abp_col]\n",
    "    ppg = segment_data.p_signal[:,ppg_col]\n",
    "    fs = segment_data.fs\n",
    "\n",
    "    print(f\"Extracted the ABP signal from column {abp_col} of the matrix of waveform data at {fs:.1f} Hz.\")\n",
    "    print(f\"Extracted the PPG signal from column {ppg_col} of the matrix of waveform data at {fs:.1f} Hz.\")\n",
    "    \n",
    "    # package\n",
    "    import scipy.signal as sp\n",
    "\n",
    "    # filter cut-offs\n",
    "    lpf_cutoff = 0.7 # Hz\n",
    "    hpf_cutoff = 10 # Hz\n",
    "\n",
    "    # create filter\n",
    "    sos_filter = sp.butter(10, [lpf_cutoff, hpf_cutoff],\n",
    "                       btype = 'bp',\n",
    "                       analog = False,\n",
    "                       output = 'sos',\n",
    "                       fs = fs)\n",
    "\n",
    "    # filter PPG\n",
    "    ppg_filt = sp.sosfiltfilt(sos_filter, ppg)\n",
    "\n",
    "    # Filter ABP\n",
    "    abp_filt = sp.sosfiltfilt(sos_filter, abp)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    temp_fs = 125\n",
    "\n",
    "    ppg_ibis_d2max = pulse_detect(ppg_filt, temp_fs, 5, 'd2max')\n",
    "    #if ppg_ibis_d2max:\n",
    "    print(f\"Detected {len(ppg_ibis_d2max)} beats in the PPG signal using the {'D2max'} algorithm\")\n",
    "\n",
    "    ppg_ibis_upslopes = pulse_detect(ppg_filt, temp_fs, 5,'upslopes')\n",
    "    #if ppg_ibis_upslopes:\n",
    "    print(f\"Detected {len(ppg_ibis_upslopes)} beats in the PPG signal using the {'Upslopes'} algorithm\")\n",
    "\n",
    "    ppg_ibis_delineator = pulse_detect(ppg_filt, temp_fs, 5, 'delineator')\n",
    "    #if ppg_ibis_delineator:\n",
    "    print(f\"Detected {len(ppg_ibis_delineator)} beats in the PPG signal using the {'Delineator'} algorithm\")\n",
    "   \n",
    "    Heart_Rate = 3*len(ppg_ibis_upslopes)\n",
    "    \n",
    "\n",
    "    \n",
    "    temp_fs = 125\n",
    "    alg = 'd2max'\n",
    "\n",
    "    \n",
    "    pks = fidp[\"pks\"]\n",
    "    ons = fidp[\"ons\"]\n",
    "    t = np.arange(0,(len(abp)/fs),1.0/fs)\n",
    "    plt.plot(t, abp, color = 'black')\n",
    "    plt.plot(t[pks], abp[pks], \".\", color = 'red')\n",
    "    plt.plot(t[ons], abp[ons], \".\", color = 'blue')\n",
    "    \n",
    "    \n",
    "    pks = fidp[\"pks\"]\n",
    "    ons = fidp[\"ons\"]\n",
    "    t = np.arange(0,(len(abp)/fs),1.0/fs)\n",
    "\n",
    "    sbp = np.median(abp[fidp['pks']])\n",
    "    dbp = np.median(abp[fidp['ons']])\n",
    "    \n",
    "    df.at[rel_segment_no, 'Heart_Rate'] = Heart_Rate\n",
    "    df.at[rel_segment_no, 'Systolic_blood_pressure(SBP)'] = sbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507769b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b0174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Systolic_blood_pressure(SBP)']!= 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43abc7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97067fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using apply function to create a new column\n",
    "\n",
    "df['Shock_index'] = df['Heart_Rate']/df['Systolic_blood_pressure(SBP)']\n",
    "\n",
    "# Print the DataFrame after addition\n",
    "# of new column\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c744e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Systolic_blood_pressure(SBP)']!= 0.0]\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62320698",
   "metadata": {},
   "outputs": [],
   "source": [
    " df['Shock_index'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07281a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [a if np.isnan(a) else 1 if a>1.0 else 0 for a in df.Shock_index]\n",
    "df['critically ill'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c324f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5084fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe\n",
    "df.to_csv('Shock_index.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59334f",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "1. https://wfdb.io/mimic_wfdb_tutorials/intro.html\n",
    "\n",
    "2. https://physionet.org/content/mimic4wdb/0.1.0/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f9aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
